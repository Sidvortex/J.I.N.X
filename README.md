```markdown
<div align="center">

# âš¡ J.I.N.X. âš¡
### **Judgmental Intelligence with Neural eXecution**

![Version](https://img.shields.io/badge/version-2.0.77-cyan?style=for-the-badge)
![Status](https://img.shields.io/badge/status-ACTIVE-brightgreen?style=for-the-badge)
![License](https://img.shields.io/badge/license-MIT-purple?style=for-the-badge)
![Python](https://img.shields.io/badge/python-3.10+-blue?style=for-the-badge&logo=python)
![ESP32](https://img.shields.io/badge/ESP32-WROOM--32-red?style=for-the-badge)

<br>

*An autonomous AI-powered robotic assistant with real-time computer vision, 
voice interaction, environmental awareness, and adaptive personality â€” 
built from electronic waste.*

<br>

**B.Tech Final Year Project â€” Data Science (2023-2027)**

<br>

[Features](#-features) Â· 
[Architecture](#-system-architecture) Â· 
[Hardware](#-hardware) Â· 
[ML Models](#-ml-models) Â· 
[Installation](#-installation) Â· 
[Usage](#-usage) Â· 
[Demo](#-demo-day) Â· 
[License](#-license)

</div>

---

## ğŸ“Œ About

**J.I.N.X.** is a multi-modal AI robotic assistant that sees, hears, 
speaks, moves, and judges â€” all built from recycled electronic 
components, a spare smartphone, a dead laptop, and low-cost 
microcontrollers within a budget of â‚¹4,000.

It combines **10 machine learning models** spanning computer vision, 
audio processing, natural language understanding, network security, 
and multi-modal sensor fusion into a single autonomous mobile platform 
with a cyberpunk aesthetic and a sarcastic personality.

> *"JINX was born from a dead ThinkPad T61. A laptop from 2007 that 
> couldn't even turn on anymore. Its metal chassis became JINX's body. 
> Its screws hold JINX together. A spare phone that couldn't make calls 
> became JINX's eyes, ears, and voice. Total hardware cost: â‚¹4,000. 
> This project proves that AI isn't about expensive hardware â€” it's 
> about intelligence."*

---

## ğŸ¯ Problem Statement

Current AI and robotics projects in academic settings typically require 
expensive hardware such as GPUs, dedicated AI development boards, and 
premium sensors, making them inaccessible to students with limited 
budgets. Additionally, most existing systems focus on single-modal 
intelligence (vision-only or voice-only), lacking the multi-sensory 
integration needed for truly autonomous and interactive robotic behavior.

**JINX** addresses both challenges by developing a fully functional AI 
robotic assistant using recycled electronics, low-cost microcontrollers, 
and open-source ML frameworks â€” achieving multi-modal intelligence 
(vision + audio + language + IoT) at a total hardware cost under â‚¹4,000.

---

## ğŸ¯ Objectives

1. To develop a multi-modal AI robotic system capable of real-time face 
   detection, recognition, and classification of known, unknown, and 
   flagged individuals using computer vision techniques.

2. To implement pose estimation and gesture recognition for intuitive 
   human-robot interaction and device control.

3. To build and train a Convolutional Neural Network (CNN) for real-time 
   environmental audio classification and anomaly detection.

4. To integrate Natural Language Processing (NLP) for voice-command-based 
   control, conversational AI interaction, and context-aware humor 
   generation using Large Language Models.

5. To design an IoT-based sensor fusion system combining visual, auditory, 
   and proximity sensor data for intelligent decision-making and 
   autonomous navigation.

6. To develop a cyberpunk-themed real-time monitoring dashboard for 
   centralized data visualization, alert logging, and system management.

7. To implement autonomous power management with battery monitoring and 
   self-docking behavior.

8. To demonstrate sustainable engineering practices by constructing the 
   system primarily from recycled and repurposed electronic components 
   within a constrained budget.

---

## âœ¨ Features

### ğŸ¤– Core Capabilities

| Feature | Description |
|---|---|
| ğŸ‘ï¸ **Face Detection & Recognition** | Detects faces in real-time, recognizes known individuals, flags unknown and threat-marked persons with color-coded bounding boxes (ğŸŸ¢ Known Safe, ğŸ”µ Unknown, ğŸ”´ Threat) |
| ğŸ¦´ **Pose Estimation** | 33-keypoint body skeleton tracking with neon glow overlay in real-time |
| ğŸ–ï¸ **Gesture Control** | Hand gesture recognition (21 keypoints per hand) to control LED lights and robot behavior |
| ğŸ­ **468-Point Face Mesh** | Real-time facial landmark mesh for dramatic scanning visual effects |
| ğŸ”Š **Audio Classification** | CNN-based environmental sound detection â€” glass breaking, screams, sirens, dog barking, gunshots, normal speech |
| ğŸ—£ï¸ **Voice Commands** | Wake-word activated voice control â€” "Hey JINX, [command]" |
| ğŸ’¬ **Conversational AI** | Gemini Pro LLM-powered conversations with context-aware sarcastic personality |
| ğŸ”¥ **Roast Mode** | AI-generated personalized comedic roasts using face recognition + LLM |
| ğŸµ **Music Playback** | Voice-activated music search and playback |
| ğŸ’¡ **Light Control** | IoT-based LED strip control via voice commands and gestures |
| ğŸ›¡ï¸ **Network Monitoring** | Real-time network device detection and traffic anomaly analysis |
| ğŸš¨ **Surveillance Mode** | Autonomous patrol with face/object/sound threat detection and alert logging |

### ğŸ¨ Physical Features

| Feature | Description |
|---|---|
| ğŸ‘€ **Animated Eyes** | 2.4" TFT display showing 11 emotional eye states (happy, angry, sleepy, love, scanning, threat, roast, music, thinking, surprised, neutral) |
| ğŸ”„ **Head Tracking** | Pan-tilt servo mechanism â€” JINX physically turns its head to follow detected faces |
| ğŸ‘ï¸ **Pupil Tracking** | Digital eye pupils follow face position on screen synchronized with head movement |
| ğŸ—ï¸ **Metal Tank Chassis** | All-metal tracked platform for stable indoor navigation |
| ğŸ”‹ **Battery Management** | 7.4V 18650 Li-ion pack with BMS, voltage monitoring, and low-battery dock-seeking behavior |
| ğŸ“¦ **Storage Unit** | Physical compartment for storing HDDs and USB drives |
| ğŸ”Œ **Charging Dock** | Self-navigating dock return with "charge me please" personality behavior |
| ğŸŒˆ **Reactive LED System** | WS2812B addressable LED strip that changes color/pattern based on JINX's mood, alerts, and modes |
| ğŸ”Š **Built-in Speaker** | DFPlayer Mini + 3W speaker for voice output and sound effects from JINX's body |
| â™»ï¸ **Recycled Body** | Chassis decorated with ThinkPad keyboard keys, RAM sticks, HDD platters, vent grills with LED backlighting |

### ğŸ§  Operating Modes

```
MODE 1: BUDDY MODE (Default)
â”œâ”€â”€ Friendly personality, responds to commands
â”œâ”€â”€ Plays music, controls lights, answers questions
â”œâ”€â”€ Eyes follow people, head tracks faces
â”œâ”€â”€ Wanders slowly when idle
â””â”€â”€ Returns to dock when battery low

MODE 2: SENTINEL MODE (Surveillance)
â”œâ”€â”€ Active patrol and scanning
â”œâ”€â”€ Color-coded face/object detection
â”‚   â”œâ”€â”€ ğŸŸ¢ GREEN = Known + Safe
â”‚   â”œâ”€â”€ ğŸ”µ BLUE = Unknown (not in database)
â”‚   â””â”€â”€ ğŸ”´ RED = Known + Flagged as Threat
â”œâ”€â”€ Audio anomaly detection (glass break, screams)
â”œâ”€â”€ Network intrusion monitoring
â”œâ”€â”€ All events logged with timestamps + screenshots
â””â”€â”€ LED strips react to threat level

MODE 3: ROAST MODE
â”œâ”€â”€ Scans person's face
â”œâ”€â”€ Identifies them from database
â”œâ”€â”€ Generates personalized comedic roast via Gemini LLM
â”œâ”€â”€ Delivers roast through built-in speaker
â”œâ”€â”€ Eyes show smug expression
â””â”€â”€ LED strips flash party mode

MODE 4: DOCK MODE (Auto-Charging)
â”œâ”€â”€ Battery level drops below 10%
â”œâ”€â”€ Eyes become sleepy
â”œâ”€â”€ JINX says "charge me please"
â”œâ”€â”€ Follows line to charging dock
â”œâ”€â”€ Waits for user to plug in cable
â”œâ”€â”€ Eyes slowly brighten as charging progresses
â””â”€â”€ Announces "I'M BACK!" when fully charged
```

---

## ğŸ—ï¸ System Architecture

```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚     LAPTOP (Main Server)      â”‚
                    â”‚                              â”‚
                    â”‚  ğŸ§  ML Models:               â”‚
                    â”‚  â”œâ”€â”€ YOLOv5-nano             â”‚
                    â”‚  â”œâ”€â”€ MediaPipe (Face/Pose/Hand)â”‚
                    â”‚  â”œâ”€â”€ Face Recognition (dlib)  â”‚
                    â”‚  â”œâ”€â”€ Audio CNN               â”‚
                    â”‚  â”œâ”€â”€ Network Anomaly Det.     â”‚
                    â”‚  â”œâ”€â”€ Vosk STT                â”‚
                    â”‚  â”œâ”€â”€ Gemini Pro LLM          â”‚
                    â”‚  â””â”€â”€ Sensor Fusion Engine    â”‚
                    â”‚                              â”‚
                    â”‚  ğŸŒ Server:                   â”‚
                    â”‚  â”œâ”€â”€ Flask / FastAPI          â”‚
                    â”‚  â”œâ”€â”€ MQTT Broker (Mosquitto)  â”‚
                    â”‚  â”œâ”€â”€ SQLite Database          â”‚
                    â”‚  â””â”€â”€ WebSocket Server         â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                          WiFi ROUTER
                     (Private Network)
                               â”‚
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚                  â”‚                  â”‚
     â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
     â”‚   J.I.N.X.  â”‚   â”‚   TABLET    â”‚   â”‚   PHONE     â”‚
     â”‚   ROBOT     â”‚   â”‚  DASHBOARD  â”‚   â”‚  (Remote    â”‚
     â”‚             â”‚   â”‚             â”‚   â”‚   Control)  â”‚
     â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚   â”‚  Cyberpunk  â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚ â”‚ ESP32   â”‚ â”‚   â”‚  Command    â”‚
     â”‚ â”‚-Motors  â”‚ â”‚   â”‚  Center     â”‚
     â”‚ â”‚-Servos  â”‚ â”‚   â”‚             â”‚
     â”‚ â”‚-Display â”‚ â”‚   â”‚ -Camera Feedâ”‚
     â”‚ â”‚-LEDs    â”‚ â”‚   â”‚ -Face Scan  â”‚
     â”‚ â”‚-Sensors â”‚ â”‚   â”‚ -Pose View  â”‚
     â”‚ â”‚-Speaker â”‚ â”‚   â”‚ -Audio Viz  â”‚
     â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚   â”‚ -Network    â”‚
     â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚   â”‚ -Alerts     â”‚
     â”‚ â”‚ REDMI   â”‚ â”‚   â”‚ -Battery    â”‚
     â”‚ â”‚ NOTE 12 â”‚ â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚ â”‚-Camera  â”‚ â”‚
     â”‚ â”‚-Mic     â”‚ â”‚
     â”‚ â”‚-Speaker â”‚ â”‚
     â”‚ â”‚-Display â”‚ â”‚
     â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Data Flow

```
VISION PIPELINE:
Phone Camera â†’ WiFi Stream â†’ Laptop Server â†’ 
ML Processing (YOLO + MediaPipe + face_recognition) â†’ 
Processed Frame â†’ Tablet Dashboard + MQTT Commands â†’ 
ESP32 (eyes + LEDs + head servos)

VOICE PIPELINE:
Bluetooth Mic â†’ Laptop Server â†’ Vosk STT â†’ 
Intent Classification â†’ Command Execution / 
Gemini API â†’ TTS Response â†’ Phone Speaker + 
DFPlayer Sound Effects

AUDIO PIPELINE:
Wired Mic â†’ Laptop Server â†’ MFCC/Mel Spectrogram â†’ 
Audio CNN â†’ Classification â†’ Alert System â†’ 
ESP32 (LEDs + buzzer + eyes)

SENSOR PIPELINE:
Ultrasonic + IR Sensors â†’ ESP32 â†’ MQTT â†’ 
Laptop Server â†’ Navigation Decisions â†’ 
MQTT â†’ ESP32 (motors)

NETWORK PIPELINE:
WiFi Router Traffic â†’ Laptop (scapy) â†’ 
Feature Extraction â†’ Anomaly Detection Model â†’ 
Dashboard + Alerts
```

### Communication Protocol

```
MQTT TOPICS:
â”œâ”€â”€ jinx/eyes          Server â†’ ESP32    Eye state commands
â”œâ”€â”€ jinx/head_track    Server â†’ ESP32    Face position for head servos
â”œâ”€â”€ jinx/eye_track     Server â†’ ESP32    Face position for pupil tracking
â”œâ”€â”€ jinx/motor         Server â†’ ESP32    Movement commands
â”œâ”€â”€ jinx/led           Server â†’ ESP32    LED pattern commands
â”œâ”€â”€ jinx/sound         Server â†’ ESP32    Sound effect triggers
â”œâ”€â”€ jinx/buzzer        Server â†’ ESP32    Buzzer commands
â”œâ”€â”€ jinx/sensors       ESP32 â†’ Server    Ultrasonic + IR data
â”œâ”€â”€ jinx/battery       ESP32 â†’ Server    Battery voltage + percentage
â”œâ”€â”€ jinx/status        ESP32 â†’ Server    System status
â”œâ”€â”€ jinx/frame         Server â†’ Tablet   Processed camera frames
â”œâ”€â”€ jinx/audio         Server â†’ Tablet   Audio classification results
â”œâ”€â”€ jinx/alerts        Server â†’ Tablet   Alert notifications
â”œâ”€â”€ jinx/mode          Server â†’ ESP32    Mode switching
â””â”€â”€ jinx/command       Server â†’ ESP32    General commands
```

---

## ğŸ”§ Hardware

### Components Purchased

| # | Component | Specification | Qty | Purpose |
|---|---|---|---|---|
| 1 | All Metal Tank Chassis Kit | Aluminum, 2Ã— DC geared motors, rubber treads, sprockets | 1 | Mobility platform |
| 2 | ESP32-WROOM-32 DevKit V1 | 30-pin, WiFi + BT, CP2102/CH340 USB | 1 | Robot microcontroller |
| 3 | 2.4" TFT LCD Display | ILI9341, SPI, 240Ã—320, 65K color | 1 | Animated eye display |
| 4 | SG90 Micro Servo Motor | 180Â°, 1.8 kg-cm torque, 4.8-6V | 2 | Head pan + tilt |
| 5 | L298N Motor Driver Module | Dual H-Bridge, 5-35V input | 1 | DC motor control |
| 6 | HC-SR04 Ultrasonic Sensor | 2-400cm range, 5V | 2 | Obstacle avoidance |
| 7 | IR Obstacle Sensor Module | Digital output, adjustable | 2 | Line following / dock navigation |
| 8 | Active Buzzer Module | 5V, active type | 1 | Alert sounds |
| 9 | 18650 Li-ion Battery Cell | 3.7V, 2600mAh, flat-top | 4 | Power source (2S2P = 7.4V) |
| 10 | 2S BMS Protection Board | 7.4V, 10-20A | 1 | Battery safety |
| 11 | 18650 Battery Holder | 4-slot, 2S2P | 1 | Battery housing |
| 12 | TP4056 Charging Module | 5V Micro-USB, 1A, with protection | 2 | Battery charging |
| 13 | 10kÎ© Resistor | 1/4W carbon film | 2 | Voltage divider (battery monitor) |
| 14 | Mini Rocker Switch | SPST ON/OFF | 1 | Main power switch |
| 15 | DFPlayer Mini | MP3, UART, Micro SD | 1 | Sound effects playback |
| 16 | Mini Speaker | 3W, 4Î©, 40mm | 1 | Audio output |
| 17 | WS2812B LED Strip | 30 LEDs, 5V, addressable | 1 | Reactive mood lighting |
| 18 | Jumper Wires M-M | 20cm, 40pc | 1 | Wiring |
| 19 | Jumper Wires M-F | 20cm, 40pc | 1 | Wiring |
| 20 | Solderless Breadboard | 840 tie points | 1 | Prototyping |

### Recycled / Pre-owned Components

| # | Component | Source | Purpose |
|---|---|---|---|
| 21 | Metal chassis parts, screws, hinges, fan, speaker, keyboard keys, RAM sticks, HDD platters | Lenovo ThinkPad T61 (non-functional) | Robot body structure + cyberpunk decoration |
| 22 | Camera, microphone, speaker, display, WiFi, sensors | Xiaomi Redmi Note 12 (spare) | Primary sensor array |
| 23 | WiFi Router | Pre-owned | Private local network |
| 24 | Tablet | UP Government issued | Dashboard display |
| 25 | Bluetooth Microphone | Pre-owned | Voice command input |
| 26 | Wired Microphone | Pre-owned | Audio classification input |
| 27 | LED Strips | Pre-owned | Room ambiance lighting |
| 28 | USB-C Chargers + Adapters | Pre-owned | Charging dock |
| 29 | Vibration motor, magnets, copper wire | Non-functional Oppo phone + earphones | Harvested components |
| 30 | Power Bank | Pre-owned | User phone charging (stored on robot) |
| 31 | Micro SD Card | Pre-owned | DFPlayer sound storage |

### GPIO Pin Mapping

```
ESP32 GPIO ALLOCATION:

TFT DISPLAY (ILI9341):          MOTORS (via L298N):
â”œâ”€â”€ GPIO 18 â†’ SCK                â”œâ”€â”€ GPIO 25 â†’ IN1
â”œâ”€â”€ GPIO 23 â†’ MOSI               â”œâ”€â”€ GPIO 26 â†’ IN2
â”œâ”€â”€ GPIO 15 â†’ CS                 â”œâ”€â”€ GPIO 27 â†’ IN3
â”œâ”€â”€ GPIO  2 â†’ DC                 â”œâ”€â”€ GPIO 14 â†’ IN4
â”œâ”€â”€ GPIO  4 â†’ RST                â”œâ”€â”€ GPIO 32 â†’ ENA (PWM)
â””â”€â”€ 3.3V   â†’ VCC + LED           â””â”€â”€ GPIO 33 â†’ ENB (PWM)

SERVOS (Pan-Tilt Head):          SENSORS:
â”œâ”€â”€ GPIO 19 â†’ Pan Servo           â”œâ”€â”€ GPIO  5 â†’ US1 TRIG
â””â”€â”€ GPIO 21 â†’ Tilt Servo          â”œâ”€â”€ GPIO 34 â†’ US1 ECHO
                                  â”œâ”€â”€ GPIO  0 â†’ US2 TRIG
LED STRIP (WS2812B):              â”œâ”€â”€ GPIO 35 â†’ US2 ECHO
â””â”€â”€ GPIO 13 â†’ DATA                â”œâ”€â”€ GPIO 36 â†’ IR Left
                                  â””â”€â”€ GPIO 39 â†’ IR Right
BUZZER:
â””â”€â”€ GPIO 12 â†’ Signal             BATTERY MONITOR:
                                  â””â”€â”€ GPIO 39 â†’ ADC (Voltage Divider)
DFPLAYER MINI:
â”œâ”€â”€ GPIO 17 â†’ TX (ESPâ†’DF)        POWER:
â””â”€â”€ GPIO 16 â†’ RX (DFâ†’ESP)        â”œâ”€â”€ VIN â† 5V (from L298N regulator)
                                  â””â”€â”€ GND â† Common Ground
```

### Power System

```
18650 Battery Pack (2S2P):
7.4V, ~5000mAh
â”‚
â”œâ”€â”€ Rocker Switch (ON/OFF)
â”‚
â”œâ”€â”€ 2S BMS (overcharge/discharge protection)
â”‚
â”œâ”€â”€â–º L298N Motor Driver (7.4V input)
â”‚    â”œâ”€â”€ Motors (get ~6V after driver drop)
â”‚    â””â”€â”€ 5V Regulator Output
â”‚         â”œâ”€â”€ ESP32 (via VIN)
â”‚         â”œâ”€â”€ Servos
â”‚         â”œâ”€â”€ LED Strip
â”‚         â”œâ”€â”€ DFPlayer
â”‚         â”œâ”€â”€ Sensors
â”‚         â””â”€â”€ Buzzer
â”‚
â”œâ”€â”€â–º Voltage Divider (10kÎ© + 10kÎ©)
â”‚    â””â”€â”€ ESP32 ADC (battery monitoring)
â”‚
â””â”€â”€â–º TP4056 Modules (for charging)
     â””â”€â”€ Micro-USB input from wall charger

Estimated Runtime: 3-4 hours (typical use)
Charging Time: ~2-3 hours
```

---

## ğŸ§  ML Models

| # | Model | Task | Type | Dataset | Key Metric |
|---|---|---|---|---|---|
| 1 | YOLOv5-nano | Object Detection | Pre-trained + fine-tuned | COCO | mAP |
| 2 | MediaPipe Face Mesh | 468-point Face Landmarks | Pre-trained | Google | Detection Accuracy |
| 3 | MediaPipe Pose | 33-point Body Pose Estimation | Pre-trained | Google | Keypoint Confidence |
| 4 | MediaPipe Hands + Custom Classifier | Hand Gesture Recognition | Pre-trained + Custom | Google + Custom | Gesture Accuracy |
| 5 | dlib ResNet / FaceNet | Face Recognition (128-d embeddings) | Pre-trained + Custom DB | LFW + Custom | FAR / FRR |
| 6 | Custom CNN (2D Conv) | Audio Event Classification | Trained from scratch | UrbanSound8K / ESC-50 | F1-Score, Accuracy |
| 7 | Vosk / Google Speech API | Speech-to-Text | Pre-trained | â€” | WER |
| 8 | Gemini Pro (LLM) | NLU + Conversation + Humor | Pre-trained API | Google | Response Relevance |
| 9 | Random Forest / XGBoost / Autoencoder | Network Anomaly Detection | Trained | NSL-KDD / CICIDS2017 | ROC-AUC, Precision |
| 10 | Weighted Ensemble | Multi-modal Sensor Fusion | Custom Designed | â€” | Detection Accuracy, FAR |

### Model Details

#### 1. Object Detection (YOLOv5-nano)
```
Architecture: YOLOv5-nano (1.9M parameters)
Input: 640Ã—640 RGB frame
Output: Bounding boxes + class labels + confidence
Classes: 80 COCO classes (person, car, dog, etc.)
Speed: ~30ms per frame on CPU
Use: Detecting people, vehicles, animals in surveillance mode
```

#### 2-4. MediaPipe Suite
```
Face Mesh: 468 3D facial landmarks, real-time
Pose: 33 body keypoints, full skeleton
Hands: 21 keypoints per hand, up to 2 hands
All run on CPU, no GPU required
Use: Visual effects, gesture control, scanning animations
```

#### 5. Face Recognition
```
Method: 128-dimensional face embedding comparison
Encoding: dlib's ResNet face encoder
Matching: Cosine similarity / Euclidean distance
Threshold: 0.5 (adjustable)
Database: Local SQLite with known face encodings
Classification: Safe (green) / Unknown (blue) / Threat (red)
```

#### 6. Audio Classification CNN
```
Architecture:
â”œâ”€â”€ Input: 128Ã—128 Mel Spectrogram (1 channel)
â”œâ”€â”€ Conv2D(32, 3Ã—3) â†’ ReLU â†’ MaxPool(2Ã—2)
â”œâ”€â”€ Conv2D(64, 3Ã—3) â†’ ReLU â†’ MaxPool(2Ã—2)
â”œâ”€â”€ Conv2D(64, 3Ã—3) â†’ ReLU â†’ MaxPool(2Ã—2)
â”œâ”€â”€ Flatten
â”œâ”€â”€ Dense(128) â†’ ReLU â†’ Dropout(0.3)
â””â”€â”€ Dense(10) â†’ Softmax

Features: Mel Spectrogram + MFCC
Classes: air_conditioner, car_horn, children_playing,
         dog_bark, drilling, engine_idling, gun_shot,
         jackhammer, siren, street_music
Dataset: UrbanSound8K (8,732 samples)
Training: 80/20 split, 50 epochs, Adam optimizer
```

#### 9. Network Anomaly Detection
```
Models tested: Random Forest, XGBoost, Autoencoder
Best: XGBoost (highest ROC-AUC)
Features: Packet size, protocol, flags, duration, 
          byte count, port numbers
Dataset: NSL-KDD (125,973 training samples)
Classes: Normal vs Anomalous traffic
```

#### 10. Sensor Fusion
```
Inputs:
â”œâ”€â”€ Visual threat score (0-1) from face recognition
â”œâ”€â”€ Audio threat score (0-1) from sound classification
â”œâ”€â”€ Network threat score (0-1) from anomaly detection
â”œâ”€â”€ Proximity alert (0/1) from ultrasonic sensors

Fusion Method: Weighted average with learned weights
Output: Combined threat score (0-1)
Threshold: > 0.7 = ALERT
```

---

## ğŸ› ï¸ Tech Stack

### Software

```
LANGUAGE          â”‚ PURPOSE
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Python 3.10+      â”‚ Main server, ML models
C++ (Arduino)     â”‚ ESP32 firmware
HTML/CSS/JS       â”‚ Dashboard styling
SQL               â”‚ Database queries

FRAMEWORK/LIBRARY â”‚ PURPOSE
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Flask / FastAPI    â”‚ Backend API server
OpenCV             â”‚ Image processing
MediaPipe          â”‚ Face mesh, pose, hands
face_recognition   â”‚ Face detection + recognition
dlib               â”‚ Face encoding (ResNet)
Ultralytics        â”‚ YOLOv5 object detection
TensorFlow/Keras   â”‚ Audio classification CNN
librosa            â”‚ Audio feature extraction
scikit-learn       â”‚ Network anomaly models
Vosk               â”‚ Offline speech recognition
pyttsx3            â”‚ Text-to-speech engine
Google Generative AIâ”‚ Gemini Pro LLM API
paho-mqtt          â”‚ MQTT communication
Streamlit          â”‚ Cyberpunk dashboard
Plotly             â”‚ Data visualization
pandas             â”‚ Data processing
SQLite3            â”‚ Event/alert database
scapy              â”‚ Network packet analysis
yt-dlp             â”‚ Music search/download
pygame             â”‚ Audio playback

ARDUINO LIBRARIES  â”‚ PURPOSE
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
TFT_eSPI           â”‚ TFT display (eye animations)
Adafruit NeoPixel  â”‚ WS2812B LED strip control
PubSubClient       â”‚ MQTT client
ArduinoJson        â”‚ JSON parsing
ESP32Servo         â”‚ Servo motor control
DFRobotDFPlayerMiniâ”‚ MP3 sound effects
NewPing            â”‚ Ultrasonic sensor reading
```

### Hardware Architecture

```
SERVER LAYER:     Personal Laptop (Python + ML)
NETWORK LAYER:    WiFi Router (MQTT + HTTP)
CONTROLLER LAYER: ESP32-WROOM-32 (Motor + Sensor + Display)
SENSOR LAYER:     Redmi Note 12 (Camera + Mic)
DISPLAY LAYER:    UP Govt Tablet (Dashboard) + TFT (Eyes)
ACTUATOR LAYER:   Motors + Servos + LEDs + Speaker + Buzzer
POWER LAYER:      18650 2S2P Pack (7.4V) + BMS + TP4056
```

---

## ğŸ“ Project Structure

```
JINX/
â”œâ”€â”€ server/
â”‚   â”œâ”€â”€ main.py                  # Main entry point â€” starts all systems
â”‚   â”œâ”€â”€ vision.py                # Computer vision pipeline
â”‚   â”œâ”€â”€ voice.py                 # Voice commands + TTS + Gemini
â”‚   â”œâ”€â”€ audio_classifier.py      # Audio event classification
â”‚   â”œâ”€â”€ network_monitor.py       # Network anomaly detection
â”‚   â”œâ”€â”€ mqtt_handler.py          # MQTT communication manager
â”‚   â”œâ”€â”€ database.py              # SQLite event/alert logging
â”‚   â”œâ”€â”€ sensor_fusion.py         # Multi-modal threat scoring
â”‚   â””â”€â”€ personality.py           # Personality lines + responses
â”‚
â”œâ”€â”€ dashboard/
â”‚   â”œâ”€â”€ app.py                   # Streamlit cyberpunk dashboard
â”‚   â”œâ”€â”€ styles.css               # Neon/cyberpunk CSS theme
â”‚   â””â”€â”€ assets/
â”‚       â”œâ”€â”€ fonts/               # Orbitron, Share Tech Mono
â”‚       â””â”€â”€ icons/               # Dashboard icons
â”‚
â”œâ”€â”€ arduino/
â”‚   â””â”€â”€ jinx_esp32/
â”‚       â”œâ”€â”€ jinx_esp32.ino       # Main ESP32 firmware
â”‚       â”œâ”€â”€ eyes.h               # Eye animation functions
â”‚       â”œâ”€â”€ motors.h             # Motor control functions
â”‚       â”œâ”€â”€ leds.h               # LED pattern functions
â”‚       â”œâ”€â”€ sensors.h            # Sensor reading functions
â”‚       â”œâ”€â”€ servos.h             # Head pan-tilt functions
â”‚       â””â”€â”€ config.h             # Pin definitions + WiFi config
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ audio_classifier.h5      # Trained audio CNN model
â”‚   â”œâ”€â”€ network_anomaly.pkl      # Trained network model
â”‚   â”œâ”€â”€ vosk-model/              # Offline speech recognition model
â”‚   â””â”€â”€ yolov5n.pt               # YOLOv5-nano weights
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ known_faces/             # Registered face images
â”‚   â”‚   â”œâ”€â”€ admin.jpg
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ alerts/                  # Alert screenshots
â”‚   â”œâ”€â”€ urbansound8k/            # Audio training dataset
â”‚   â”œâ”€â”€ nsl-kdd/                 # Network training dataset
â”‚   â””â”€â”€ jinx_database.db         # SQLite database
â”‚
â”œâ”€â”€ training/
â”‚   â”œâ”€â”€ train_audio_cnn.py       # Audio model training script
â”‚   â”œâ”€â”€ train_network_model.py   # Network model training script
â”‚   â””â”€â”€ evaluate_models.py       # Model evaluation + metrics
â”‚
â”œâ”€â”€ assets/
â”‚   â”œâ”€â”€ personality.json         # Personality lines database
â”‚   â””â”€â”€ sounds/                  # MP3 sound effects for DFPlayer
â”‚       â”œâ”€â”€ 001_boot.mp3
â”‚       â”œâ”€â”€ 002_alert.mp3
â”‚       â”œâ”€â”€ 003_happy.mp3
â”‚       â”œâ”€â”€ 004_threat.mp3
â”‚       â”œâ”€â”€ 005_sleepy.mp3
â”‚       â””â”€â”€ 006_ambient.mp3
â”‚
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ report.pdf               # Final project report
â”‚   â”œâ”€â”€ presentation.pptx        # Demo presentation
â”‚   â”œâ”€â”€ wiring_diagram.png       # Hardware wiring diagram
â”‚   â”œâ”€â”€ architecture_diagram.png # System architecture
â”‚   â””â”€â”€ demo_video.mp4           # Recorded demo backup
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ README.md                    # This file
â”œâ”€â”€ LICENSE                      # MIT License
â””â”€â”€ .gitignore                   # Git ignore rules
```

---

## âš¡ Installation

### Prerequisites

```
- Personal Laptop (Windows/Linux/Mac)
- Python 3.10 or higher
- Arduino IDE 2.x
- Git
- Assembled JINX robot hardware
- WiFi Router configured
- Redmi Note 12 with IP Webcam app
- UP Govt Tablet with browser
```

### Step 1: Clone Repository

```bash
git clone https://github.com/sidvortex/JINX.git
cd JINX
```

### Step 2: Python Environment Setup

```bash
# Create virtual environment
python -m venv jinx_env

# Activate
# Windows:
jinx_env\Scripts\activate
# Linux/Mac:
source jinx_env/bin/activate

# Install dependencies
pip install -r requirements.txt
```

### Step 3: Download ML Models

```bash
# YOLOv5 (auto-downloads on first run)
python -c "from ultralytics import YOLO; YOLO('yolov5n.pt')"

# Vosk speech model
# Download from: https://alphacephei.com/vosk/models
# Extract to: models/vosk-model/

# Audio model (train or use pre-trained)
python training/train_audio_cnn.py
```

### Step 4: Configure API Keys

```bash
# Create .env file
echo "GEMINI_API_KEY=your_api_key_here" > .env

# Get free API key from:
# https://aistudio.google.com/
```

### Step 5: Configure Network

```bash
# Edit server/config.py
LAPTOP_IP = "192.168.1.10"
PHONE_IP = "192.168.1.11"
TABLET_IP = "192.168.1.12"
ESP32_IP = "192.168.1.20"
MQTT_PORT = 1883
CAMERA_URL = "http://192.168.1.11:8080/video"
```

### Step 6: Flash ESP32

```
1. Open Arduino IDE
2. Open arduino/jinx_esp32/jinx_esp32.ino
3. Install required libraries (TFT_eSPI, NeoPixel, 
   PubSubClient, ArduinoJson, ESP32Servo, DFPlayer)
4. Configure TFT_eSPI User_Setup.h for ILI9341
5. Select Board: ESP32 Dev Module
6. Select Port: COMx / /dev/ttyUSBx
7. Upload
```

### Step 7: Setup Phone

```
1. Install "IP Webcam" from Play Store
2. Connect to WiFi router (static IP: 192.168.1.11)
3. Open IP Webcam â†’ Start Server
4. Verify: http://192.168.1.11:8080/video in browser
```

### Step 8: Register Faces

```bash
# Add face images to data/known_faces/
# Filename = person's name
# Example: data/known_faces/admin.jpg
#          data/known_faces/amit_friend.jpg
#          data/known_faces/threat_person.jpg

# Update labels in server/config.py
FACE_LABELS = {
    "admin": "safe",
    "amit_friend": "safe",
    "threat_person": "threat"
}
```

---

## ğŸš€ Usage

### Starting JINX

```bash
# Terminal 1: Start MQTT Broker
mosquitto -v

# Terminal 2: Start JINX Core Server
cd JINX
source jinx_env/bin/activate
python server/main.py

# Terminal 3: Start Dashboard
streamlit run dashboard/app.py --server.port 8501

# On Tablet: Open browser â†’ http://192.168.1.10:8501
# On Phone: Start IP Webcam
# On Robot: Power ON (rocker switch)
```

### Boot Sequence

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘     â–ˆâ–ˆâ•—â–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ•—   â–ˆâ–ˆâ•—â–ˆâ–ˆâ•—  â–ˆâ–ˆâ•—             â•‘
â•‘     â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•             â•‘
â•‘     â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â–ˆâ–ˆâ•— â–ˆâ–ˆâ•‘ â•šâ–ˆâ–ˆâ–ˆâ•”â•              â•‘
â•‘â–ˆâ–ˆ   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘ â–ˆâ–ˆâ•”â–ˆâ–ˆâ•—              â•‘
â•‘â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘ â•šâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â• â–ˆâ–ˆâ•—            â•‘
â•‘ â•šâ•â•â•â•â• â•šâ•â•â•šâ•â•  â•šâ•â•â•â•â•šâ•â•  â•šâ•â•            â•‘
â•‘                                           â•‘
â•‘  JUDGMENTAL INTELLIGENCE WITH              â•‘
â•‘  NEURAL EXECUTION v2.0.77                 â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

[INIT] Loading MQTT Broker........... âœ“
[INIT] Loading Neural Engine......... âœ“
[INIT] Loading Optic Pipeline........ âœ“
[INIT] Loading Echo Scanner.......... âœ“
[INIT] Loading Voice Core............ âœ“
[INIT] Loading Personality Matrix.... âœ“
[INIT] Loading Motor Controller...... âœ“
[INIT] Loading Dashboard Server...... âœ“

âš¡ JINX NEURAL CORE ONLINE âš¡
```

### Voice Commands

```
"Hey JINX, wake up"              â†’ System activation
"Hey JINX, guard mode"           â†’ Sentinel surveillance mode
"Hey JINX, roast [name]"         â†’ AI-generated roast
"Hey JINX, play music"           â†’ Music playback
"Hey JINX, lights [color]"       â†’ LED control (red/blue/green/purple/party)
"Hey JINX, come here"            â†’ Move forward
"Hey JINX, go back"              â†’ Move backward
"Hey JINX, search [topic]"       â†’ Web search + summarize
"Hey JINX, what's the weather?"  â†’ Weather information
"Hey JINX, goodnight"            â†’ Sleep mode
```

---

## ğŸ¬ Demo Day

### Room Setup

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  â–‘â–‘â–‘â–‘â–‘â–‘ LED STRIPS (PURPLE BREATHING) â–‘â–‘â–‘â–‘â–‘ â”‚
â”‚                                              â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚   â”‚ LAPTOP  â”‚  â”‚   TABLET     â”‚              â”‚
â”‚   â”‚ Terminal â”‚  â”‚  DASHBOARD   â”‚              â”‚
â”‚   â”‚ (Matrix) â”‚  â”‚  (Cyberpunk) â”‚              â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚                                              â”‚
â”‚          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                        â”‚
â”‚          â”‚ J.I.N.X. â”‚  â† The Star            â”‚
â”‚          â”‚   ğŸ¤–     â”‚                        â”‚
â”‚          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                        â”‚
â”‚                           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚                           â”‚CHARGINGâ”‚         â”‚
â”‚                           â”‚ DOCK   â”‚         â”‚
â”‚                           â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â”‚                                              â”‚
â”‚  â–‘â–‘â–‘â–‘â–‘â–‘ LED STRIPS (PURPLE BREATHING) â–‘â–‘â–‘â–‘â–‘ â”‚
â”‚                                              â”‚
â”‚       ğŸ‘¥ AUDIENCE ğŸ‘¥                         â”‚
â”‚                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Demo Script

```
1. Room is dark. LED strips breathing purple.
2. "Hey JINX, wake up."
   â†’ Boot animation, eyes open, LEDs flash cyan
3. Step in front â†’ face recognized â†’ green box â†’ "Hey boss!"
4. Friend steps in â†’ unknown â†’ blue box â†’ scanned and logged
5. "Hey JINX, roast [friend]" â†’ AI roast delivered
6. "Hey JINX, guard mode" â†’ scanning eyes, surveillance active
7. Play glass breaking sound â†’ threat detected â†’ red alert
8. "Hey JINX, play music" â†’ music + LED light show
9. "Hey JINX, lights purple" â†’ room changes color
10. "Hey JINX, goodnight" â†’ sleepy eyes â†’ system standby
```

---

## ğŸ”‹ Power Specifications

```
Battery: 4Ã— 18650 Li-ion (2S2P)
Voltage: 7.4V nominal (8.4V full, 6.0V cutoff)
Capacity: ~5000mAh
Runtime: 3-4 hours (typical)
Charging: TP4056 via Micro-USB (5V 1A)
Charge Time: 2-3 hours
Protection: 2S BMS (overcharge, over-discharge, short circuit)
Monitoring: ESP32 ADC via voltage divider
```

---

## ğŸ’° Budget

| Category | Cost (â‚¹) |
|---|---|
| Metal Tank Chassis Kit | 900 |
| ESP32 + Display | 800 |
| Servos + Motor Driver | 290 |
| Sensors + Buzzer | 225 |
| Battery + BMS + Charger + Switch | 565 |
| DFPlayer + Speaker | 160 |
| LED Strip | 250 |
| Wiring + Breadboard | 230 |
| Build Materials | 330 |
| **Total** | **~â‚¹3,750** |

> Recycled components from ThinkPad T61, spare phone, existing 
> peripherals saved an estimated â‚¹15,000+ in equivalent hardware costs.

---

## ğŸ“Š Results & Metrics

| Model | Metric | Score |
|---|---|---|
| YOLOv5-nano | mAP@0.5 | 28.0% (COCO) |
| Face Recognition | Accuracy | ~95%+ |
| Face Recognition | False Acceptance Rate | <2% |
| Pose Estimation | Keypoint Confidence | ~90%+ |
| Audio CNN | F1-Score | ~85%+ |
| Audio CNN | Accuracy | ~88%+ |
| Network Anomaly | ROC-AUC | ~92%+ |
| Voice Recognition | Word Error Rate | ~10-15% |
| Sensor Fusion | Overall Detection Accuracy | ~90%+ |

> *Metrics to be updated after final training and evaluation.*

---

## ğŸ”® Future Scope

```
â”œâ”€â”€ Spider leg mechanism (servo-based hexapod conversion)
â”œâ”€â”€ SLAM-based room mapping and path planning
â”œâ”€â”€ Raspberry Pi 4 integration for on-robot ML processing
â”œâ”€â”€ Robotic arm attachment for object manipulation
â”œâ”€â”€ Multi-robot swarm communication
â”œâ”€â”€ Cloud dashboard for remote monitoring
â”œâ”€â”€ Mobile app for remote control
â”œâ”€â”€ Emotion detection from facial expressions
â”œâ”€â”€ Multi-language voice support (Hindi + English)
â”œâ”€â”€ Integration with smart home ecosystems (Google Home, Alexa)
â””â”€â”€ 3D-printed custom chassis upgrade
```

---

## ğŸ‘¨â€ğŸ’» Author

```
[Your Name]
B.Tech Data Science (2023-2027)
[Your College Name]
[Your University]

Email: [your.email@example.com]
GitHub: github.com/yourusername
LinkedIn: linkedin.com/in/yourprofile
```

---

## ğŸ“œ License

This project is licensed under the MIT License â€” see the [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgments

```
â”œâ”€â”€ Google MediaPipe team (vision models)
â”œâ”€â”€ Ultralytics (YOLOv5)
â”œâ”€â”€ dlib / face_recognition library
â”œâ”€â”€ Google Gemini AI
â”œâ”€â”€ DFRobot (DFPlayer Mini)
â”œâ”€â”€ Espressif Systems (ESP32)
â”œâ”€â”€ The dead ThinkPad T61 that gave its body for science
â”œâ”€â”€ Open-source community
â””â”€â”€ [Your Professor's Name] (Project Guide)
```

---

<div align="center">

**Built with â™¥, sarcasm, and â‚¹3,750 worth of components.**

**JINX doesn't just think. It judges.**

âš¡ğŸ¤–âš¡

</div>

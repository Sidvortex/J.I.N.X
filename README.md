<div align="center">

# ğŸ¤– J.I.N.X
### **Judgmental AI Desk Companion**

![Version](https://img.shields.io/badge/version-2.1.0-cyan?style=for-the-badge)
![Status](https://img.shields.io/badge/status-ACTIVE-brightgreen?style=for-the-badge)
![License](https://img.shields.io/badge/license-MIT-purple?style=for-the-badge)
![Python](https://img.shields.io/badge/python-3.10+-blue?style=for-the-badge&logo=python)
![ESP32](https://img.shields.io/badge/ESP32-WROOM--32-red?style=for-the-badge)
![Budget](https://img.shields.io/badge/budget-â‚¹4%2C550-yellow?style=for-the-badge)

<br>

*An autonomous AI desk robot with real-time computer vision, human-like voice,
face recognition, skeleton tracking, document Q&A, live code review,
home automation, and a sarcastic personality â€” built from electronic waste.*

<br>

**B.Tech Final Year Project â€” Data Science (2023â€“2027)**

<br>

[Features](#-features) Â·
[Architecture](#-system-architecture) Â·
[Hardware](#-hardware) Â·
[ML Models](#-ml-models) Â·
[Installation](#-installation) Â·
[Usage](#-usage) Â·
[Codex](#-codex) Â·
[Demo](#-demo-setup) Â·
[License](#-license)

</div>

---

## ğŸ“Œ About

**J.I.N.X** is a multi-modal AI robotic desk companion that sees, hears, speaks, judges, and even reviews your code â€” all built from recycled electronics, a spare smartphone, a dead ThinkPad, and low-cost microcontrollers within a budget of â‚¹4,550.

It combines **10 machine learning models** spanning computer vision, audio classification, natural language understanding, network security, and sensor fusion into a single desk-mounted platform with a cyberpunk aesthetic and an attitude problem.

> *"Born from a dead ThinkPad T61 that couldn't even turn on anymore. Its metal chassis became J.I.N.X's body. A spare phone that couldn't make calls became its eyes, ears, and voice. Total hardware cost: â‚¹4,550. This project proves that AI isn't about expensive hardware â€” it's about intelligence."*

---

## ğŸ¯ Problem Statement

AI robotics projects in academic settings typically require expensive GPUs, dedicated AI boards, and premium sensors â€” inaccessible to students on tight budgets. Most systems also focus on a single modality (vision-only or voice-only), lacking the multi-sensory integration needed for truly autonomous and useful robotic behavior.

**J.I.N.X** addresses both challenges: a fully multi-modal AI companion using recycled electronics, low-cost microcontrollers, and open-source ML frameworks at under â‚¹4,600 total.

---

## ğŸ¯ Objectives

1. Develop a multi-modal AI system capable of real-time face detection, recognition, and classification (safe / unknown / threat) using computer vision.
2. Implement pose estimation and gesture recognition for human-robot interaction and device control.
3. Build and train a CNN for environmental audio classification and anomaly detection.
4. Integrate NLP for voice-command control and conversational AI using Gemini LLM with a human-sounding neural TTS voice.
5. Build an AI agent capable of answering questions from uploaded documents and reviewing live code.
6. Design an IoT sensor fusion system combining visual, audio, proximity, and depth sensor data for intelligent decision-making.
7. Implement depth-aware safety (table edge detection using VL53L0X ToF sensors) and autonomous battery management.
8. Demonstrate sustainable engineering by constructing the system primarily from recycled components under a constrained budget.

---

## âœ¨ Features

### ğŸ§  AI & Intelligence

| Feature | Description |
|---|---|
| ğŸ‘ï¸ **Face Detection & Recognition** | Detects and recognizes faces in real-time. Color-coded bounding boxes: ğŸŸ¢ Known Safe, ğŸ”µ Unknown, ğŸ”´ Flagged Threat |
| ğŸ¦´ **Skeleton / Pose Estimation** | 33-keypoint full body skeleton overlay â€” use it to analyze posture, show off during a dance, or detect falls |
| ğŸ–ï¸ **Gesture Control** | 21-keypoint hand gesture recognition â€” control LEDs, change modes, trigger actions without touching anything |
| ğŸ­ **Face Mesh** | 468-point real-time facial landmark mesh â€” dramatic scanning visual effect |
| ğŸ”Š **Audio Classification** | CNN-trained on UrbanSound8K â€” detects gunshots, sirens, glass breaking, screams, dog barks in real-time |
| ğŸ—£ï¸ **Wake Word + Voice Commands** | "Hey JINX, [command]" â€” offline wake word detection, full voice control |
| ğŸ’¬ **Conversational AI** | Gemini 2.0 Flash-powered conversations with context memory and sarcastic personality |
| ğŸ™ï¸ **Human Voice (edge-TTS)** | Microsoft Neural TTS â€” sounds like a real human, not a robot. Free. No API key needed |
| ğŸ“„ **Document Q&A** | Upload PDFs, books, notes to `data/documents/` â€” ask J.I.N.X questions about them by voice or web |
| ğŸ’» **Code Review Agent** | Point it at your project folder â€” auto-reviews changed files on save, flags bugs, security issues, style problems |
| ğŸ”¥ **Roast Mode** | Scans your face, identifies you, generates a personalized AI roast via Gemini, delivers it through the speaker |
| ğŸµ **Music Playback** | Voice-activated music search and streaming via yt-dlp + mpv |
| ğŸ’¡ **Home Automation** | IoT LED strip + smart device control via voice and gesture |
| ğŸ›¡ï¸ **Network Monitor** | Detects all devices on WiFi, flags unknown/new devices, traffic anomaly detection |

### ğŸ¤– Physical & Mechanical

| Feature | Description |
|---|---|
| ğŸ‘€ **Animated Eyes** | 2.4" TFT display with 12 emotional states: neutral, happy, angry, sleepy, love, scanning, threat, roast, music, thinking, talking, boot |
| ğŸ”„ **Head Tracking** | Pan-tilt servo mechanism â€” J.I.N.X physically turns its head to follow detected faces |
| ğŸ‘ï¸ **Pupil Tracking** | Digital eye pupils follow face position on the TFT display, synchronized with servo movement |
| ğŸ“ **Table Edge Detection** | VL53L0X ToF sensor facing downward â€” detects desk edges with millimeter accuracy, stops motors instantly |
| ğŸš§ **Obstacle Avoidance** | Dual HC-SR04 ultrasonic + forward VL53L0X â€” stops before hitting anything |
| ğŸ”‹ **Battery Management** | 7.4V 18650 2S2P pack, BMS protection, voltage monitoring via ESP32 ADC |
| ğŸ”” **Low Battery Alert** | At <15%: eyes go sleepy, LEDs pulse yellow, J.I.N.X says *"I'm running on spite"* |
| ğŸŒˆ **Reactive LED System** | WS2812B strip with 11 animated modes â€” reacts to mood, threats, music, and battery level |
| ğŸ”Š **Built-in Speaker** | DFPlayer Mini + 3W speaker for sound effects. Neural TTS plays through phone speaker |
| â™»ï¸ **Recycled Body** | ThinkPad T61 chassis, keyboard keys, RAM sticks, HDD platters as decoration |

### ğŸŒ Control & Interface

| Feature | Description |
|---|---|
| ğŸ“± **Web Control Panel** | Phone/tablet browser UI at `http://LAPTOP_IP:5000` â€” live feed, mode switching, LED colors, movement, document upload, code paste |
| ğŸ–¥ï¸ **Streamlit Dashboard** | Cyberpunk command center at port 8501 â€” camera feed, skeleton view, network map, audio viz, alert log |
| ğŸ“² **Remote Control** | Any device on the same WiFi can control J.I.N.X from a browser â€” no app needed |

---

### ğŸ”€ Operating Modes

```
MODE 1: BUDDY (Default)
â”œâ”€â”€ Friendly personality, responds to voice commands
â”œâ”€â”€ Answers questions, plays music, controls lights
â”œâ”€â”€ Eyes follow people, head tracks faces
â”œâ”€â”€ Skeleton overlay shows your movements in real-time
â””â”€â”€ Returns low-battery warning when needed

MODE 2: SENTINEL (Surveillance)
â”œâ”€â”€ Active scanning â€” color-coded face + object detection
â”‚   â”œâ”€â”€ ğŸŸ¢ GREEN  = Known + Safe
â”‚   â”œâ”€â”€ ğŸ”µ BLUE   = Unknown (not in database)
â”‚   â””â”€â”€ ğŸ”´ RED    = Known + Flagged as Threat
â”œâ”€â”€ Audio anomaly detection (glass break, screams, gunshots)
â”œâ”€â”€ Network device monitoring â€” flags unknown WiFi devices
â”œâ”€â”€ All events logged with timestamps + screenshots
â””â”€â”€ LED strips react to threat level in real-time

MODE 3: ROAST
â”œâ”€â”€ Scans person's face â†’ identifies from database
â”œâ”€â”€ Generates personalized comedic roast via Gemini
â”œâ”€â”€ Delivers roast through speaker in human voice
â”œâ”€â”€ Eyes show smug expression, LEDs flash orange party mode
â””â”€â”€ Adjustable intensity: light / medium / savage

MODE 4: AGENT
â”œâ”€â”€ Document Q&A â€” ask questions about uploaded PDFs/books
â”œâ”€â”€ Code review â€” watches your project folder, reviews on save
â”œâ”€â”€ Image search â€” "what does a golden retriever look like?"
â”œâ”€â”€ Research assistant â€” searches web for answers
â””â”€â”€ Read document aloud â€” summarizes books by voice command

MODE 5: SLEEP
â”œâ”€â”€ Eyes close, LEDs dim
â”œâ”€â”€ Wake word still active
â””â”€â”€ "I was in the middle of something."
```

---

## ğŸ—ï¸ System Architecture

```
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚       LAPTOP (Main Server)        â”‚
                â”‚                                  â”‚
                â”‚  ğŸ§  ML Models:                   â”‚
                â”‚  â”œâ”€â”€ YOLOv5-nano (object detect)  â”‚
                â”‚  â”œâ”€â”€ MediaPipe (Face/Pose/Hands)   â”‚
                â”‚  â”œâ”€â”€ face_recognition (dlib)      â”‚
                â”‚  â”œâ”€â”€ Audio CNN (UrbanSound8K)     â”‚
                â”‚  â”œâ”€â”€ Vosk STT (offline)           â”‚
                â”‚  â”œâ”€â”€ edge-TTS (neural voice)      â”‚
                â”‚  â”œâ”€â”€ Gemini 2.0 Flash (LLM)       â”‚
                â”‚  â”œâ”€â”€ Network Anomaly (RF)         â”‚
                â”‚  â””â”€â”€ Sensor Fusion (Hivemind)     â”‚
                â”‚                                  â”‚
                â”‚  ğŸŒ Services:                     â”‚
                â”‚  â”œâ”€â”€ Python Backend               â”‚
                â”‚  â”œâ”€â”€ MQTT Broker (Mosquitto)      â”‚
                â”‚  â”œâ”€â”€ Flask Web Control (:5000)    â”‚
                â”‚  â”œâ”€â”€ Streamlit Dashboard (:8501)  â”‚
                â”‚  â””â”€â”€ SQLite Database              â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                           WiFi Router
                      (Private Local Network)
                                â”‚
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚                     â”‚                      â”‚
   â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
   â”‚  J.I.N.X    â”‚      â”‚   TABLET    â”‚        â”‚   PHONE     â”‚
   â”‚  ROBOT      â”‚      â”‚  DASHBOARD  â”‚        â”‚  (Control   â”‚
   â”‚             â”‚      â”‚             â”‚        â”‚   Panel)    â”‚
   â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚      â”‚  â”€ Camera   â”‚        â”‚             â”‚
   â”‚ â”‚  ESP32  â”‚ â”‚      â”‚  â”€ Skeleton â”‚        â”‚ http://     â”‚
   â”‚ â”‚â”€Motors  â”‚ â”‚      â”‚  â”€ Network  â”‚        â”‚ LAPTOP:5000 â”‚
   â”‚ â”‚â”€Servos  â”‚ â”‚      â”‚  â”€ Alerts   â”‚        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   â”‚ â”‚â”€TFT Eyesâ”‚ â”‚      â”‚  â”€ Audio    â”‚
   â”‚ â”‚â”€LEDs    â”‚ â”‚      â”‚  â”€ Battery  â”‚
   â”‚ â”‚â”€Sensors â”‚ â”‚      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   â”‚ â”‚â”€Speaker â”‚ â”‚
   â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
   â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
   â”‚ â”‚Redmi 12 â”‚ â”‚
   â”‚ â”‚â”€Camera  â”‚ â”‚
   â”‚ â”‚â”€Mic     â”‚ â”‚
   â”‚ â”‚â”€Speaker â”‚ â”‚  â† Neural TTS voice plays here
   â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Data Flow Pipelines

```
VISION:   Phone Camera â†’ WiFi â†’ Laptop â†’ YOLO + MediaPipe + face_recognition
          â†’ Annotated Frame â†’ Tablet Dashboard + MQTT â†’ ESP32 (eyes/LEDs/servos)

VOICE:    Microphone â†’ Laptop â†’ Vosk STT â†’ Command Parser / Gemini LLM
          â†’ edge-TTS â†’ Phone Speaker + DFPlayer Sound Effects

AUDIO:    Mic â†’ Laptop â†’ Mel Spectrogram â†’ CNN â†’ Alert System
          â†’ ESP32 (LEDs/buzzer/eyes)

DEPTH:    VL53L0X (down) â†’ ESP32 â†’ MQTT â†’ Laptop â†’ Stop motor if edge detected
          VL53L0X (fwd)  â†’ ESP32 â†’ MQTT â†’ Laptop â†’ Stop if obstacle < 15cm

NETWORK:  WiFi Router â†’ scapy â†’ Device Scanner â†’ Anomaly Model
          â†’ Dashboard + Alerts

FUSION:   Visual + Audio + Network + Proximity scores â†’ Weighted average
          â†’ doom_level (0â€“1) â†’ LED color + eye state + alert log
```

---

## ğŸ”§ Hardware

### Purchased Components (~â‚¹3,750 from original JINX build + ~â‚¹800 additions)

| # | Component | Spec | Purpose |
|---|---|---|---|
| 1 | ESP32-WROOM-32 DevKit | WiFi+BT, 30-pin | Robot brain |
| 2 | 2.4" TFT ILI9341 | 240Ã—320, SPI | Animated eyes |
| 3 | SG90 Servo (Ã—2) | 180Â°, 1.8kg-cm | Head pan + tilt |
| 4 | L298N Motor Driver | Dual H-Bridge | DC motor control |
| 5 | HC-SR04 Ultrasonic (Ã—2) | 2-400cm | Obstacle detection |
| 6 | **VL53L0X ToF Sensor (Ã—2)** | 2m, Â±1mm, I2C | Table edge + precise obstacle depth |
| 7 | IR Sensor (Ã—2) | Digital output | Secondary edge detection |
| 8 | WS2812B LED Strip | 30 LEDs, 5V | Mood reactive lighting |
| 9 | DFPlayer Mini + 3W Speaker | UART, MP3 | Sound effects |
| 10 | 18650 Battery (Ã—4) | 3.7V 2600mAh | 2S2P = 7.4V ~5000mAh |
| 11 | 2S BMS Board | 7.4V 10A | Battery protection |
| 12 | TP4056 Modules (Ã—2) | 5V 1A | Charging |
| 13 | Active Buzzer | 5V | Alerts |
| 14 | 10kÎ© Resistors (Ã—4) | 1/4W | Voltage divider |
| 15 | Jumper Wires + Breadboard | â€” | Wiring |

> **Why VL53L0X over IR for depth?** IR sensors only give "object yes/no". The VL53L0X gives exact distance in millimeters via I2C â€” so J.I.N.X knows it's 5mm from a table edge vs 50mm, and can react proportionally.

### Recycled / Pre-owned

| Component | Source | Purpose |
|---|---|---|
| Metal parts, keyboard keys, RAM, HDD platters, fan | Lenovo ThinkPad T61 | Body structure + decoration |
| Camera, mic, speaker, display, WiFi | Xiaomi Redmi Note 12 | Primary sensor array + neural TTS speaker |
| Tablet | UP Govt issued | Dashboard display |
| WiFi Router | Pre-owned | Private local network |
| Bluetooth Mic | Pre-owned | Voice input |

**Total hardware cost: ~â‚¹4,550**
Recycled components saved an estimated â‚¹15,000+ in equivalent hardware costs.

### GPIO Pin Mapping

```
TFT DISPLAY (ILI9341):        I2C BUS (VL53L0X):
â”œâ”€â”€ GPIO 18 â†’ SCK             â”œâ”€â”€ GPIO 21 â†’ SDA
â”œâ”€â”€ GPIO 23 â†’ MOSI            â””â”€â”€ GPIO 22 â†’ SCL
â”œâ”€â”€ GPIO 15 â†’ CS              (TOF1 XSHUT â†’ GPIO 13)
â”œâ”€â”€ GPIO 2  â†’ DC              (TOF2 XSHUT â†’ GPIO 12)
â””â”€â”€ GPIO 4  â†’ RST

SERVOS (Pan-Tilt):            MOTORS (L298N):
â”œâ”€â”€ GPIO 19 â†’ Pan             â”œâ”€â”€ GPIO 25 â†’ IN1
â””â”€â”€ GPIO 11 â†’ Tilt            â”œâ”€â”€ GPIO 26 â†’ IN2
                              â”œâ”€â”€ GPIO 27 â†’ IN3
LED STRIP (WS2812B):          â”œâ”€â”€ GPIO 14 â†’ IN4
â””â”€â”€ GPIO 16 â†’ DATA            â”œâ”€â”€ GPIO 32 â†’ ENA (PWM)
                              â””â”€â”€ GPIO 33 â†’ ENB (PWM)
ULTRASONIC:
â”œâ”€â”€ GPIO 5/34 â†’ US1 TRIG/ECHO BATTERY ADC:
â””â”€â”€ GPIO 0/35 â†’ US2 TRIG/ECHO â””â”€â”€ GPIO 35 â†’ ADC (voltage divider)

DFPLAYER: GPIO 16(RX), 17(TX)
BUZZER:   GPIO 12
IR:       GPIO 36, 39
```

---

## ğŸ§  ML Models

| # | Model | Task | Type | Dataset |
|---|---|---|---|---|
| 1 | YOLOv5-nano | Object Detection | Pre-trained | COCO (80 classes) |
| 2 | MediaPipe Face Mesh | 468-point Landmarks | Pre-trained | Google |
| 3 | MediaPipe Pose | 33-point Skeleton | Pre-trained | Google |
| 4 | MediaPipe Hands + Classifier | Gesture Recognition | Pre-trained + Custom | Google + Custom |
| 5 | dlib ResNet / face_recognition | Face Recognition (128-d embeddings) | Pre-trained + Custom DB | LFW + Your faces |
| 6 | Custom CNN (2D Conv) | Audio Classification | Trained from scratch | UrbanSound8K |
| 7 | Vosk / Google STT | Speech-to-Text | Pre-trained | â€” |
| 8 | Gemini 2.0 Flash | NLU + Conversation + Agent | API | Google |
| 9 | Random Forest | Network Anomaly Detection | Trained | NSL-KDD |
| 10 | Weighted Ensemble | Sensor Fusion | Custom | â€” |

### Audio CNN Architecture

```
Input: 128Ã—128 Mel Spectrogram
  â”‚
  â”œâ”€â”€ Conv2D(32, 3Ã—3) â†’ BatchNorm â†’ ReLU â†’ MaxPool(2Ã—2)
  â”œâ”€â”€ Conv2D(64, 3Ã—3) â†’ BatchNorm â†’ ReLU â†’ MaxPool(2Ã—2)
  â”œâ”€â”€ Conv2D(128, 3Ã—3) â†’ BatchNorm â†’ ReLU â†’ MaxPool(2Ã—2)
  â”œâ”€â”€ Conv2D(64, 3Ã—3) â†’ GlobalAveragePooling
  â”œâ”€â”€ Dense(256) â†’ ReLU â†’ Dropout(0.4)
  â”œâ”€â”€ Dense(128) â†’ ReLU â†’ Dropout(0.3)
  â””â”€â”€ Dense(10) â†’ Softmax

Classes: air_conditioner, car_horn, children_playing, dog_bark,
         drilling, engine_idling, gun_shot, jackhammer, siren, street_music
Dataset: UrbanSound8K (8,732 samples)
```

### Sensor Fusion (Hivemind)

```
Visual Score  (0â€“1) Ã— 0.35  â†  face_recognition threat level
Audio Score   (0â€“1) Ã— 0.30  â†  CNN threat-class confidence
Network Score (0â€“1) Ã— 0.20  â†  anomaly model prediction
Proximity     (0â€“1) Ã— 0.15  â†  ultrasonic + ToF distances
                    â†“
              doom_level (0â€“1)
              > 0.70 â†’ ALERT â†’ LED + eyes + buzzer + log
```

---

## ğŸ“– Codex

All modules use cyberpunk-inspired codenames.

| File | Codename | Purpose |
|---|---|---|
| `genesis.py` | GENESIS | Main startup â€” launches everything |
| `dna.py` | DNA | All configuration and settings |
| `blackbox.py` | BLACKBOX | SQLite event logging |
| `psyche.py` | PSYCHE | Personality, jokes, roast prompts |
| `optic.py` | OPTIC | Vision â€” camera, faces, pose, mesh, gestures |
| `vocoder.py` | VOCODER | Voice â€” STT, neural TTS, Gemini, commands, music |
| `echo_hunter.py` | ECHO HUNTER | Audio â€” CNN sound classification |
| `ice_wall.py` | ICE WALL | Network â€” device scan, anomaly detection |
| `synapse.py` | SYNAPSE | MQTT â€” all inter-module messaging |
| `hivemind.py` | HIVEMIND | Sensor fusion â€” doom level scoring |
| `agent.py` | AGENT | AI Agent â€” document Q&A + code review |
| `nexus.py` | NEXUS | Streamlit cyberpunk dashboard |
| `web_control/app.py` | NEXUS-WEB | Flask phone control panel |

---

## ğŸ“ Project Structure

```
J.I.N.X/
â”‚
â”œâ”€â”€ server/
â”‚   â”œâ”€â”€ genesis.py          # Main startup + module orchestration
â”‚   â”œâ”€â”€ dna.py              # All config (IPs, API keys, thresholds)
â”‚   â”œâ”€â”€ blackbox.py         # SQLite logging
â”‚   â”œâ”€â”€ psyche.py           # Personality + humor system
â”‚   â”œâ”€â”€ optic.py            # Vision pipeline
â”‚   â”œâ”€â”€ vocoder.py          # Voice system (STT + neural TTS + Gemini)
â”‚   â”œâ”€â”€ echo_hunter.py      # Audio CNN
â”‚   â”œâ”€â”€ ice_wall.py         # Network monitoring
â”‚   â”œâ”€â”€ synapse.py          # MQTT hub
â”‚   â”œâ”€â”€ hivemind.py         # Sensor fusion
â”‚   â””â”€â”€ agent.py            # Document Q&A + code review agent
â”‚
â”œâ”€â”€ dashboard/
â”‚   â””â”€â”€ nexus.py            # Streamlit cyberpunk dashboard (:8501)
â”‚
â”œâ”€â”€ web_control/
â”‚   â”œâ”€â”€ app.py              # Flask control server (:5000)
â”‚   â””â”€â”€ templates/
â”‚       â””â”€â”€ index.html      # Phone/browser UI
â”‚
â”œâ”€â”€ arduino/
â”‚   â””â”€â”€ jinx_esp32/
â”‚       â”œâ”€â”€ jinx_esp32.ino  # Main firmware
â”‚       â”œâ”€â”€ config.h           # Pin definitions + WiFi + MQTT topics
â”‚       â”œâ”€â”€ eyes.h             # TFT animated eye states (12 modes)
â”‚       â”œâ”€â”€ motors.h           # L298N DC motor control
â”‚       â”œâ”€â”€ sensors.h          # Ultrasonic + VL53L0X + IR + Battery + DFPlayer
â”‚       â””â”€â”€ servos.h           # Pan-tilt head servo (smooth interpolation)
â”‚
â”œâ”€â”€ training/
â”‚   â””â”€â”€ train_audio_cnn.py     # CNN training on UrbanSound8K
â”‚
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ register_face.py       # Add faces to database (file or live camera)
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ audio_classifier.h5    # Trained audio CNN (generated)
â”‚   â”œâ”€â”€ network_anomaly.pkl    # Trained network model (generated)
â”‚   â””â”€â”€ vosk-model/            # Offline STT model (downloaded)
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ known_faces/           # Face images â€” filename = person name
â”‚   â”œâ”€â”€ documents/             # Upload PDFs/books here for agent Q&A
â”‚   â”œâ”€â”€ alerts/                # Auto-saved alert screenshots
â”‚   â””â”€â”€ jinx_database.db       # SQLite database (auto-generated)
â”‚
â”œâ”€â”€ assets/sounds/             # MP3 files for DFPlayer
â”œâ”€â”€ BUILD_GUIDE.md             # Full hardware assembly guide
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## âš¡ Installation

### Prerequisites

```
Personal laptop (Linux recommended, Windows/Mac also work)
Python 3.10+
Arduino IDE 2.x
Assembled J.I.N.X hardware
WiFi router (private network)
Redmi Note 12 with DroidCam installed
Mosquitto MQTT broker
cmake (for face_recognition/dlib)
mpv (for audio/music playback)
```

### Step 1 â€” Clone

```bash
git clone https://github.com/Sidvortex/J.I.N.X.git
cd J.I.N.X
```

### Step 2 â€” Install Dependencies

```bash
# Ubuntu/Debian
sudo apt install mosquitto cmake libcmake-data espeak-ng mpv yt-dlp \
                 portaudio19-dev python3-pip

# Arch/EndeavourOS
sudo pacman -S mosquitto cmake espeak-ng mpv yt-dlp portaudio python-pip

# Python packages
pip install -r requirements.txt

# Start MQTT broker
sudo systemctl enable --now mosquitto
```

### Step 3 â€” Configure

```bash
cp server/dna.py server/dna.py.example
nano server/dna.py

# Set:
LAPTOP_IP       = "your.laptop.ip"
PHONE_IP        = "redmi.note.ip"
GEMINI_API_KEY  = "get from aistudio.google.com"
FACE_LABELS     = {"yourname": "safe"}
```

### Step 4 â€” Download ML Models

```bash
# Vosk offline STT model
mkdir -p models/vosk-model
# Download from: https://alphacephei.com/vosk/models
# Use: vosk-model-small-en-us-0.15 (~40MB)
# Extract contents into models/vosk-model/

# YOLOv5 (auto-downloads on first run)
python -c "from ultralytics import YOLO; YOLO('yolov5n.pt')"
```

### Step 5 â€” Train Audio Model (Optional)

```bash
# Download UrbanSound8K from:
# https://urbansounddataset.weebly.com/urbansound8k.html
# Extract to: data/urbansound8k/

python training/train_audio_cnn.py
# Takes ~30 minutes, saves to models/audio_classifier.h5
```

### Step 6 â€” Register Your Face

```bash
# From a photo file
python scripts/register_face.py --name yourname --file photo.jpg --label safe

# Or live from camera
python scripts/register_face.py --name yourname --live --label safe

# Then add to dna.py:
FACE_LABELS = {"yourname": "safe"}
```

### Step 7 â€” Flash ESP32

```
1. Open Arduino IDE 2.x
2. Open arduino/jinx_esp32/jinx_esp32.ino
3. Install libraries via Library Manager:
   TFT_eSPI, Adafruit NeoPixel, PubSubClient,
   ArduinoJson, ESP32Servo, DFRobotDFPlayerMini, VL53L0X
4. Edit arduino/jinx_esp32/config.h:
   - Set WIFI_SSID, WIFI_PASS, MQTT_BROKER
5. Configure TFT_eSPI: edit User_Setup.h in its library folder
   (see BUILD_GUIDE.md for exact settings)
6. Board: ESP32 Dev Module
7. Upload
```

### Step 8 â€” Setup Phone

```
1. Install DroidCam on Redmi Note 12
2. Connect to same WiFi network
3. Set static IP in router settings
4. Update PHONE_IP in server/dna.py
5. Open DroidCam â†’ Start Server
6. Test: http://PHONE_IP:4747/video in browser
```

---

## ğŸš€ Usage

### Starting J.I.N.X

```bash
# Normal startup
python server/genesis.py

# Start in Sentinel mode
python server/genesis.py --sentinel

# Start in Agent mode (document/code focus)
python server/genesis.py --agent-mode

# Skip modules for faster startup
python server/genesis.py --no-audio --no-network

# Individual module testing
python server/optic.py          # Vision only
python server/vocoder.py        # Voice only
python server/echo_hunter.py    # Audio only
```

### Startup Output

```
     â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•—  â–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—
     â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•‘ â–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â•â–ˆâ–ˆâ•—â•šâ•â•â–ˆâ–ˆâ•”â•â•â•
     â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â• â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘
     â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•  â•šâ•â•â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•— â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘
     â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•   â–ˆâ–ˆâ•‘
     â•šâ•â•â•â•â•â• â•šâ•â•â•â•â•â•â•â•šâ•â•â•â•â•â•â•â•šâ•â•  â•šâ•â•â•šâ•â•â•â•â•â•  â•šâ•â•â•â•â•â•    â•šâ•â•

  [INIT] Loading SYNAPSE (MQTT Bridge)............. âœ“
  [INIT] Loading BLACKBOX (Database)............... âœ“
  [INIT] Loading PSYCHE (Personality Matrix)....... âœ“
  [INIT] Loading OPTIC (Visual Cortex)............. âœ“
  [INIT] Loading VOCODER (Voice System)............ âœ“
  [INIT] Loading ECHO HUNTER (Sound Detection)..... âœ“
  [INIT] Loading ICE WALL (Network Defense)........ âœ“
  [INIT] Loading HIVEMIND (Sensor Fusion).......... âœ“
  [INIT] Loading AGENT (AI Code/Doc Agent)......... âœ“

  âš¡ J.I.N.X NEURAL CORE ONLINE âš¡
```

### Voice Commands

```
"Hey JINX, wake up"              â†’ System activation
"Hey JINX, guard mode"           â†’ Sentinel surveillance mode
"Hey JINX, buddy mode"           â†’ Switch to buddy mode
"Hey JINX, agent mode"           â†’ Document Q&A / code review mode
"Hey JINX, roast [name]"         â†’ AI-generated personalized roast
"Hey JINX, what is [topic]"      â†’ Gemini answers + shows image
"Hey JINX, play [song/genre]"    â†’ Music search and playback
"Hey JINX, lights [color]"       â†’ LED color change
"Hey JINX, come here"            â†’ Move forward
"Hey JINX, go back"              â†’ Move backward
"Hey JINX, status"               â†’ System health report
"Hey JINX, register [name]"      â†’ Save current face to database
"Hey JINX, read [document name]" â†’ Summarizes uploaded document
"Hey JINX, review my code"       â†’ Code review of watched folder
"Hey JINX, what does X look like"â†’ Image search shown on tablet
"Hey JINX, goodnight"            â†’ Sleep mode
"Hey JINX, stop music"           â†’ Stop playback
```

### Document Q&A (Agent Mode)

```bash
# Drop any PDF, text, or code file into data/documents/
cp my_textbook.pdf data/documents/
cp lecture_notes.txt data/documents/

# Then ask by voice:
"Hey JINX, what does chapter 3 say about neural networks?"
"Hey JINX, summarize the lecture notes"

# Or via web panel at http://LAPTOP_IP:5000 â†’ AI Agent tab
```

### Code Review (Agent Mode)

```bash
# In dna.py, set:
WATCH_CODE_DIR = "/path/to/your/project"

# J.I.N.X will automatically review any Python/JS/Java file
# you save in that directory and publish the review to the dashboard.

# Or paste code in the web panel â†’ Code Review tab
```

---

## ğŸ“Š Results & Metrics

| Model | Metric | Target |
|---|---|---|
| YOLOv5-nano | mAP@0.5 | 28% COCO baseline |
| Face Recognition | Accuracy | ~95%+ |
| Face Recognition | False Acceptance Rate | <2% |
| Pose Estimation | Keypoint Confidence | ~90%+ |
| Audio CNN | F1-Score | ~85%+ |
| Audio CNN | Accuracy | ~88%+ |
| Network Anomaly | ROC-AUC | ~92%+ |
| Voice Recognition | Word Error Rate | ~10-15% |
| Sensor Fusion | Detection Accuracy | ~90%+ |
| Table Edge Detection | Accuracy | ~99% (VL53L0X) |

*Metrics updated after final training and evaluation.*

---

## ğŸ’° Budget

| Category | Cost |
|---|---|
| Metal Tank Chassis Kit | â‚¹900 |
| ESP32 + TFT Display | â‚¹800 |
| Servos + Motor Driver | â‚¹290 |
| Ultrasonic + IR Sensors | â‚¹225 |
| VL53L0X ToF Sensors (Ã—2) | â‚¹300 |
| Battery + BMS + Charger | â‚¹565 |
| DFPlayer + Speaker | â‚¹160 |
| LED Strip | â‚¹250 |
| Wiring + Breadboard | â‚¹230 |
| Build Materials + Misc | â‚¹330 |
| **Total** | **~â‚¹4,550** |

Recycled components (ThinkPad T61, Redmi Note 12, tablet) saved an estimated â‚¹15,000+ in equivalent hardware.

---

## ğŸ–¥ï¸ Demo Setup

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   â–‘â–‘â–‘â–‘â–‘â–‘ LED STRIPS (PURPLE BREATHING) â–‘â–‘â–‘â–‘â–‘â–‘â–‘  â”‚
â”‚                                                  â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
â”‚   â”‚  LAPTOP  â”‚   â”‚    TABLET      â”‚             â”‚
â”‚   â”‚ genesis  â”‚   â”‚   NEXUS DASH   â”‚             â”‚
â”‚   â”‚ terminal â”‚   â”‚                â”‚             â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚ Camera Feed    â”‚             â”‚
â”‚                  â”‚ Skeleton View  â”‚             â”‚
â”‚                  â”‚ Network Map    â”‚             â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚ Alert Log      â”‚             â”‚
â”‚   â”‚ J.I.N.X  â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
â”‚   â”‚   ğŸ¤–     â”‚                                  â”‚
â”‚   â”‚  Eyes    â”‚                                  â”‚
â”‚   â”‚  LEDs    â”‚                                  â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                  â”‚
â”‚                                                  â”‚
â”‚   â–‘â–‘â–‘â–‘â–‘â–‘ LED STRIPS (PURPLE BREATHING) â–‘â–‘â–‘â–‘â–‘â–‘â–‘  â”‚
â”‚                                                  â”‚
â”‚              ğŸ‘¥ AUDIENCE ğŸ‘¥                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Demo Script

```
1.  Room lights off. LED strips breathing purple.
2.  "Hey JINX, wake up."
    â†’ Boot animation on TFT, eyes open, LEDs flash cyan.
3.  Step in front â†’ face recognized â†’ green box â†’ "Oh, it's you again."
4.  Friend steps in â†’ unknown â†’ blue box â†’ "New face detected. I'm watching you."
5.  "Hey JINX, show skeleton" â†’ pose estimation + skeleton overlay on tablet.
6.  Dance in front â†’ real-time skeleton follows your movements.
7.  "Hey JINX, guard mode" â†’ scanning eyes, face colors update, network scan.
8.  Play glass breaking sound near mic â†’ audio CNN triggers red alert.
9.  "Hey JINX, roast [friend]" â†’ Gemini-generated personalized roast delivered.
10. "Hey JINX, what does a black hole look like?" â†’ image shown on tablet.
11. "Hey JINX, play chill music" â†’ music starts, LEDs go rainbow.
12. "Hey JINX, lights purple" â†’ LEDs change color on voice command.
13. "Hey JINX, review my code" â†’ pulls latest file from watched folder, reviews it.
14. "Hey JINX, goodnight" â†’ sleepy eyes, LED dim â†’ system standby.
```

---

## ğŸ”® Future Scope

```
â”œâ”€â”€ SLAM-based room mapping and path planning
â”œâ”€â”€ Raspberry Pi 4 integration for on-robot ML (remove laptop dependency)
â”œâ”€â”€ Robotic arm for object manipulation
â”œâ”€â”€ Emotion detection from facial expressions
â”œâ”€â”€ Multi-language voice (Hindi + English)
â”œâ”€â”€ Smart home ecosystem integration (Google Home, Alexa)
â”œâ”€â”€ 3D-printed custom chassis upgrade
â”œâ”€â”€ Mobile app (React Native) for remote control
â”œâ”€â”€ Cloud dashboard for remote monitoring outside local network
â”œâ”€â”€ Multi-robot swarm communication
â””â”€â”€ Hexapod leg conversion (servo-based spider legs)
```

---

## ğŸ› ï¸ Tech Stack

```
LANGUAGE          PURPOSE
Python 3.10+    â”‚ Main server, ML models, web backend
C++ (Arduino)   â”‚ ESP32 firmware
HTML/CSS/JS     â”‚ Web control panel UI
SQL             â”‚ Database queries

LIBRARY               PURPOSE
OpenCV              â”‚ Image processing + display
MediaPipe           â”‚ Face mesh, pose estimation, hands
face_recognition    â”‚ Face detection + recognition
dlib                â”‚ Face encoding (ResNet backbone)
Ultralytics         â”‚ YOLOv5 object detection
TensorFlow/Keras    â”‚ Audio CNN
librosa             â”‚ Audio feature extraction (mel spectrogram)
scikit-learn        â”‚ Network anomaly Random Forest
Vosk                â”‚ Offline STT
edge-tts            â”‚ Microsoft Neural TTS (human voice, free)
google-generativeai â”‚ Gemini 2.0 Flash LLM
paho-mqtt           â”‚ MQTT broker communication
Flask               â”‚ Web control server
Streamlit           â”‚ Cyberpunk dashboard
scapy               â”‚ Network packet analysis
yt-dlp + mpv        â”‚ Music streaming
PyPDF2 / pypdf      â”‚ PDF text extraction
python-docx         â”‚ Word document reading
SQLite3             â”‚ Event and alert logging

ARDUINO LIBRARY       PURPOSE
TFT_eSPI            â”‚ TFT display (ILI9341) â€” eye animations
Adafruit NeoPixel   â”‚ WS2812B LED strip
PubSubClient        â”‚ MQTT client
ArduinoJson         â”‚ JSON parsing
ESP32Servo          â”‚ Servo motor control
DFRobotDFPlayerMini â”‚ MP3 sound effects via DFPlayer Mini
VL53L0X (Pololu)    â”‚ Time-of-Flight depth sensors
```

---

## ğŸ‘¨â€ğŸ’» Author

**Sidvortex**
B.Tech Data Science (2023â€“2027)

GitHub: [github.com/Sidvortex](https://github.com/Sidvortex)

---

## ğŸ“œ License

This project is licensed under the **MIT License** â€” see the [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgments

```
â”œâ”€â”€ Google MediaPipe team (vision models)
â”œâ”€â”€ Ultralytics (YOLOv5)
â”œâ”€â”€ Adam Geitgey (face_recognition library)
â”œâ”€â”€ Microsoft (edge-TTS Neural voices)
â”œâ”€â”€ Google Gemini AI
â”œâ”€â”€ Vosk / Alpha Cephei (offline STT)
â”œâ”€â”€ DFRobot (DFPlayer Mini)
â”œâ”€â”€ Espressif Systems (ESP32)
â”œâ”€â”€ Pololu (VL53L0X library)
â”œâ”€â”€ The dead ThinkPad T61 that gave its body for science
â”œâ”€â”€ The open-source community
â””â”€â”€ [Your Professor's Name] â€” Project Guide
```

---

<div align="center">

Built with â™¥, sarcasm, and â‚¹4,550 worth of components.

*J.I.N.X doesn't just think. It judges.*

âš¡ ğŸ¤– âš¡

</div>

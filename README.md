<div align="center">

# âš¡ J.I.N.X. âš¡
### **Judgmental Intelligence with Neural eXecution**

![Version](https://img.shields.io/badge/version-2.0.77-cyan?style=for-the-badge)
![Status](https://img.shields.io/badge/status-ACTIVE-brightgreen?style=for-the-badge)
![License](https://img.shields.io/badge/license-MIT-purple?style=for-the-badge)
![Python](https://img.shields.io/badge/python-3.10+-blue?style=for-the-badge&logo=python)
![ESP32](https://img.shields.io/badge/ESP32-WROOM--32-red?style=for-the-badge)

<br>

*An autonomous AI-powered robotic assistant with real-time computer vision, 
voice interaction, environmental awareness, and adaptive personality â€” 
built from electronic waste.*

<br>

**B.Tech Final Year Project â€” Data Science (2023-2027)**

<br>

[Features](#-features) Â· 
[Architecture](#-system-architecture) Â· 
[Hardware](#-hardware) Â· 
[ML Models](#-ml-models) Â· 
[Codex](#-codex) Â·
[Installation](#-installation) Â· 
[Usage](#-usage) Â· 
[Demo](#-demo-day) Â· 
[License](#-license)

</div>

---

## ğŸ“Œ About

**J.I.N.X.** is a multi-modal AI robotic assistant that sees, hears, 
speaks, moves, and judges â€” all built from recycled electronic 
components, a spare smartphone, a dead laptop, and low-cost 
microcontrollers within a budget of â‚¹4,000.

It combines **10 machine learning models** spanning computer vision, 
audio processing, natural language understanding, network security, 
and multi-modal sensor fusion into a single autonomous mobile platform 
with a cyberpunk aesthetic and a sarcastic personality.

> *"JINX was born from a dead ThinkPad T61. A laptop from 2007 that 
> couldn't even turn on anymore. Its metal chassis became JINX's body. 
> Its screws hold JINX together. A spare phone that couldn't make calls 
> became JINX's eyes, ears, and voice. Total hardware cost: â‚¹3,750. 
> This project proves that AI isn't about expensive hardware â€” it's 
> about intelligence."*

---

## ğŸ¯ Problem Statement

Current AI and robotics projects in academic settings typically require 
expensive hardware such as GPUs, dedicated AI development boards, and 
premium sensors, making them inaccessible to students with limited 
budgets. Additionally, most existing systems focus on single-modal 
intelligence (vision-only or voice-only), lacking the multi-sensory 
integration needed for truly autonomous and interactive robotic behavior.

**JINX** addresses both challenges by developing a fully functional AI 
robotic assistant using recycled electronics, low-cost microcontrollers, 
and open-source ML frameworks â€” achieving multi-modal intelligence 
(vision + audio + language + IoT) at a total hardware cost under â‚¹4,000.

---

## ğŸ¯ Objectives

1. To develop a multi-modal AI robotic system capable of real-time face 
   detection, recognition, and classification of known, unknown, and 
   flagged individuals using computer vision techniques.

2. To implement pose estimation and gesture recognition for intuitive 
   human-robot interaction and device control.

3. To build and train a Convolutional Neural Network (CNN) for real-time 
   environmental audio classification and anomaly detection.

4. To integrate Natural Language Processing (NLP) for voice-command-based 
   control, conversational AI interaction, and context-aware humor 
   generation using Large Language Models.

5. To design an IoT-based sensor fusion system combining visual, auditory, 
   and proximity sensor data for intelligent decision-making and 
   autonomous navigation.

6. To develop a cyberpunk-themed real-time monitoring dashboard for 
   centralized data visualization, alert logging, and system management.

7. To implement autonomous power management with battery monitoring and 
   self-docking behavior.

8. To demonstrate sustainable engineering practices by constructing the 
   system primarily from recycled and repurposed electronic components 
   within a constrained budget.

---

## âœ¨ Features

### ğŸ¤– Core Capabilities

| Feature | Description |
|---|---|
| ğŸ‘ï¸ **Face Detection & Recognition** | Detects faces in real-time, recognizes known individuals, flags unknown and threat-marked persons with color-coded bounding boxes (ğŸŸ¢ Known Safe, ğŸ”µ Unknown, ğŸ”´ Threat) |
| ğŸ¦´ **Pose Estimation** | 33-keypoint body skeleton tracking with neon glow overlay in real-time |
| ğŸ–ï¸ **Gesture Control** | Hand gesture recognition (21 keypoints per hand) to control LED lights and robot behavior |
| ğŸ­ **468-Point Face Mesh** | Real-time facial landmark mesh for dramatic scanning visual effects |
| ğŸ”Š **Audio Classification** | CNN-based environmental sound detection â€” glass breaking, screams, sirens, dog barking, gunshots, normal speech |
| ğŸ—£ï¸ **Voice Commands** | Wake-word activated voice control â€” "Hey JINX, [command]" |
| ğŸ’¬ **Conversational AI** | Gemini LLM-powered conversations with context-aware sarcastic personality |
| ğŸ”¥ **Roast Mode** | AI-generated personalized comedic roasts using face recognition + LLM |
| ğŸµ **Music Playback** | Voice-activated music search and playback |
| ğŸ’¡ **Light Control** | IoT-based LED strip control via voice commands and gestures |
| ğŸ›¡ï¸ **Network Monitoring** | Real-time network device detection and traffic anomaly analysis |
| ğŸš¨ **Surveillance Mode** | Autonomous patrol with face/object/sound threat detection and alert logging |

### ğŸ¨ Physical Features

| Feature | Description |
|---|---|
| ğŸ‘€ **Animated Eyes** | 2.4" TFT display showing 11 emotional eye states (happy, angry, sleepy, love, scanning, threat, roast, music, thinking, surprised, neutral) |
| ğŸ”„ **Head Tracking** | Pan-tilt servo mechanism â€” JINX physically turns its head to follow detected faces |
| ğŸ‘ï¸ **Pupil Tracking** | Digital eye pupils follow face position on screen synchronized with head movement |
| ğŸ—ï¸ **Metal Tank Chassis** | All-metal tracked platform for stable indoor navigation |
| ğŸ”‹ **Battery Management** | 7.4V 18650 Li-ion pack with BMS, voltage monitoring, and low-battery dock-seeking behavior |
| ğŸ“¦ **Storage Unit** | Physical compartment for storing HDDs and USB drives |
| ğŸ”Œ **Charging Dock** | Self-navigating dock return with "charge me please" personality behavior |
| ğŸŒˆ **Reactive LED System** | WS2812B addressable LED strip that changes color/pattern based on JINX's mood, alerts, and modes |
| ğŸ”Š **Built-in Speaker** | DFPlayer Mini + 3W speaker for voice output and sound effects from JINX's body |
| â™»ï¸ **Recycled Body** | Chassis decorated with ThinkPad keyboard keys, RAM sticks, HDD platters, vent grills with LED backlighting |

### ğŸ§  Operating Modes
MODE 1: BUDDY MODE (Default)
â”œâ”€â”€ Friendly personality, responds to commands
â”œâ”€â”€ Plays music, controls lights, answers questions
â”œâ”€â”€ Eyes follow people, head tracks faces
â”œâ”€â”€ Wanders slowly when idle
â””â”€â”€ Returns to dock when battery low

MODE 2: SENTINEL MODE (Surveillance)
â”œâ”€â”€ Active patrol and scanning
â”œâ”€â”€ Color-coded face/object detection
â”‚ â”œâ”€â”€ ğŸŸ¢ GREEN = Known + Safe
â”‚ â”œâ”€â”€ ğŸ”µ BLUE = Unknown (not in database)
â”‚ â””â”€â”€ ğŸ”´ RED = Known + Flagged as Threat
â”œâ”€â”€ Audio anomaly detection (glass break, screams)
â”œâ”€â”€ Network intrusion monitoring
â”œâ”€â”€ All events logged with timestamps + screenshots
â””â”€â”€ LED strips react to threat level

MODE 3: ROAST MODE
â”œâ”€â”€ Scans person's face
â”œâ”€â”€ Identifies them from database
â”œâ”€â”€ Generates personalized comedic roast via Gemini LLM
â”œâ”€â”€ Delivers roast through built-in speaker
â”œâ”€â”€ Eyes show smug expression
â””â”€â”€ LED strips flash party mode

MODE 4: DOCK MODE (Auto-Charging)
â”œâ”€â”€ Battery level drops below 10%
â”œâ”€â”€ Eyes become sleepy
â”œâ”€â”€ JINX says "charge me please"
â”œâ”€â”€ Follows line to charging dock
â”œâ”€â”€ Waits for user to plug in cable
â”œâ”€â”€ Eyes slowly brighten as charging progresses
â””â”€â”€ Announces "I'M BACK!" when fully charged

text


---

## ğŸ—ï¸ System Architecture
text

                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚     LAPTOP (Main Server)      â”‚
                â”‚                              â”‚
                â”‚  ğŸ§  ML Models:               â”‚
                â”‚  â”œâ”€â”€ YOLOv5-nano             â”‚
                â”‚  â”œâ”€â”€ MediaPipe (Face/Pose/Hand)â”‚
                â”‚  â”œâ”€â”€ Face Recognition (dlib)  â”‚
                â”‚  â”œâ”€â”€ Audio CNN               â”‚
                â”‚  â”œâ”€â”€ Network Anomaly Det.     â”‚
                â”‚  â”œâ”€â”€ Vosk STT                â”‚
                â”‚  â”œâ”€â”€ Gemini LLM              â”‚
                â”‚  â””â”€â”€ Sensor Fusion Engine    â”‚
                â”‚                              â”‚
                â”‚  ğŸŒ Server:                   â”‚
                â”‚  â”œâ”€â”€ Python Backend           â”‚
                â”‚  â”œâ”€â”€ MQTT Broker (Mosquitto)  â”‚
                â”‚  â”œâ”€â”€ SQLite Database          â”‚
                â”‚  â””â”€â”€ Streamlit Dashboard      â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                      WiFi ROUTER
                 (Private Network)
                           â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                  â”‚                  â”‚
 â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
 â”‚   J.I.N.X.  â”‚   â”‚   TABLET    â”‚   â”‚   PHONE     â”‚
 â”‚   ROBOT     â”‚   â”‚  DASHBOARD  â”‚   â”‚  (Remote    â”‚
 â”‚             â”‚   â”‚  (NEXUS)    â”‚   â”‚   Control)  â”‚
 â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚   â”‚             â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 â”‚ â”‚ ESP32   â”‚ â”‚   â”‚  Cyberpunk  â”‚
 â”‚ â”‚-Motors  â”‚ â”‚   â”‚  Command    â”‚
 â”‚ â”‚-Servos  â”‚ â”‚   â”‚  Center     â”‚
 â”‚ â”‚-Display â”‚ â”‚   â”‚             â”‚
 â”‚ â”‚-LEDs    â”‚ â”‚   â”‚ -Camera Feedâ”‚
 â”‚ â”‚-Sensors â”‚ â”‚   â”‚ -Face Scan  â”‚
 â”‚ â”‚-Speaker â”‚ â”‚   â”‚ -Pose View  â”‚
 â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚   â”‚ -Audio Viz  â”‚
 â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚   â”‚ -Network    â”‚
 â”‚ â”‚ REDMI   â”‚ â”‚   â”‚ -Alerts     â”‚
 â”‚ â”‚ NOTE 12 â”‚ â”‚   â”‚ -Battery    â”‚
 â”‚ â”‚-Camera  â”‚ â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 â”‚ â”‚-Mic     â”‚ â”‚
 â”‚ â”‚-Speaker â”‚ â”‚
 â”‚ â”‚-Display â”‚ â”‚
 â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
text


### Data Flow
VISION PIPELINE (OPTIC):
Phone Camera â†’ WiFi Stream â†’ Laptop Server â†’
cortex_scan() (YOLO + MediaPipe + face_recognition) â†’
Processed Frame â†’ Tablet Dashboard + MQTT â†’
ESP32 (eyes + LEDs + head servos)

VOICE PIPELINE (VOCODER):
Bluetooth Mic â†’ Laptop Server â†’ Vosk/Google STT â†’
parse_order() â†’ Command Execution /
Gemini API â†’ vocalize() â†’ Phone Speaker +
DFPlayer Sound Effects

AUDIO PIPELINE (ECHO HUNTER):
Wired Mic â†’ Laptop Server â†’ Mel Spectrogram â†’
Audio CNN â†’ freq_hunt() â†’ Alert System â†’
ESP32 (LEDs + buzzer + eyes)

SENSOR PIPELINE:
Ultrasonic + IR Sensors â†’ ESP32 â†’ MQTT â†’
Laptop Server â†’ Navigation Decisions â†’
MQTT â†’ ESP32 (motors)

NETWORK PIPELINE (ICE WALL):
WiFi Router â†’ Laptop (scapy) â†’
scan_network() â†’ Anomaly Detection â†’
Dashboard + Alerts

FUSION PIPELINE (HIVEMIND):
Visual Score + Audio Score + Network Score +
Proximity Score â†’ doom_score() â†’
Combined Threat Level â†’ Actions

text


### Communication Protocol
MQTT TOPICS:
â”œâ”€â”€ jinx/eyes Server â†’ ESP32 Eye state commands
â”œâ”€â”€ jinx/head_track Server â†’ ESP32 Face position for head servos
â”œâ”€â”€ jinx/eye_track Server â†’ ESP32 Face position for pupil tracking
â”œâ”€â”€ jinx/motor Server â†’ ESP32 Movement commands
â”œâ”€â”€ jinx/led Server â†’ ESP32 LED pattern commands
â”œâ”€â”€ jinx/sound Server â†’ ESP32 Sound effect triggers
â”œâ”€â”€ jinx/buzzer Server â†’ ESP32 Buzzer commands
â”œâ”€â”€ jinx/sensors ESP32 â†’ Server Ultrasonic + IR data
â”œâ”€â”€ jinx/battery ESP32 â†’ Server Battery voltage + percentage
â”œâ”€â”€ jinx/status ESP32 â†’ Server System status
â”œâ”€â”€ jinx/frame Server â†’ Tablet Processed camera frames
â”œâ”€â”€ jinx/audio Server â†’ Tablet Audio classification results
â”œâ”€â”€ jinx/alerts Server â†’ Tablet Alert notifications
â”œâ”€â”€ jinx/mode Server â†’ ESP32 Mode switching
â”œâ”€â”€ jinx/command Server â†’ ESP32 General commands
â”œâ”€â”€ jinx/doom_level Server â†’ Tablet Sensor fusion threat score
â””â”€â”€ jinx/network_stats Server â†’ Tablet Network device information

text


---

## ğŸ”§ Hardware

### Components Purchased

| # | Component | Specification | Qty | Purpose |
|---|---|---|---|---|
| 1 | All Metal Tank Chassis Kit | Aluminum, 2Ã— DC geared motors, rubber treads, sprockets | 1 | Mobility platform |
| 2 | ESP32-WROOM-32 DevKit V1 | 30-pin, WiFi + BT, CP2102/CH340 USB | 1 | Robot microcontroller |
| 3 | 2.4" TFT LCD Display | ILI9341, SPI, 240Ã—320, 65K color | 1 | Animated eye display |
| 4 | SG90 Micro Servo Motor | 180Â°, 1.8 kg-cm torque, 4.8-6V | 2 | Head pan + tilt |
| 5 | L298N Motor Driver Module | Dual H-Bridge, 5-35V input | 1 | DC motor control |
| 6 | HC-SR04 Ultrasonic Sensor | 2-400cm range, 5V | 2 | Obstacle avoidance |
| 7 | IR Obstacle Sensor Module | Digital output, adjustable | 2 | Line following / dock navigation |
| 8 | Active Buzzer Module | 5V, active type | 1 | Alert sounds |
| 9 | 18650 Li-ion Battery Cell | 3.7V, 2600mAh, flat-top | 4 | Power source (2S2P = 7.4V) |
| 10 | 2S BMS Protection Board | 7.4V, 10-20A | 1 | Battery safety |
| 11 | 18650 Battery Holder | 4-slot, 2S2P | 1 | Battery housing |
| 12 | TP4056 Charging Module | 5V Micro-USB, 1A, with protection | 2 | Battery charging |
| 13 | 10kÎ© Resistor | 1/4W carbon film | 2 | Voltage divider (battery monitor) |
| 14 | Mini Rocker Switch | SPST ON/OFF | 1 | Main power switch |
| 15 | DFPlayer Mini | MP3, UART, Micro SD | 1 | Sound effects playback |
| 16 | Mini Speaker | 3W, 4Î©, 40mm | 1 | Audio output |
| 17 | WS2812B LED Strip | 30 LEDs, 5V, addressable | 1 | Reactive mood lighting |
| 18 | Jumper Wires M-M | 20cm, 40pc | 1 | Wiring |
| 19 | Jumper Wires M-F | 20cm, 40pc | 1 | Wiring |
| 20 | Solderless Breadboard | 840 tie points | 1 | Prototyping |

### Recycled / Pre-owned Components

| # | Component | Source | Purpose |
|---|---|---|---|
| 21 | Metal chassis parts, screws, hinges, fan, speaker, keyboard keys, RAM sticks, HDD platters | Lenovo ThinkPad T61 (non-functional) | Robot body structure + cyberpunk decoration |
| 22 | Camera, microphone, speaker, display, WiFi, sensors | Xiaomi Redmi Note 12 (spare) | Primary sensor array |
| 23 | WiFi Router | Pre-owned | Private local network |
| 24 | Tablet | UP Government issued | Dashboard display |
| 25 | Bluetooth Microphone | Pre-owned | Voice command input |
| 26 | Wired Microphone | Pre-owned | Audio classification input |
| 27 | LED Strips | Pre-owned | Room ambiance lighting |
| 28 | USB-C Chargers + Adapters | Pre-owned | Charging dock |
| 29 | Vibration motor, magnets, copper wire | Non-functional Oppo phone + earphones | Harvested components |
| 30 | Power Bank | Pre-owned | User phone charging (stored on robot) |
| 31 | Micro SD Card | Pre-owned | DFPlayer sound storage |

### GPIO Pin Mapping
ESP32 GPIO ALLOCATION:

TFT DISPLAY (ILI9341): MOTORS (via L298N):
â”œâ”€â”€ GPIO 18 â†’ SCK â”œâ”€â”€ GPIO 25 â†’ IN1
â”œâ”€â”€ GPIO 23 â†’ MOSI â”œâ”€â”€ GPIO 26 â†’ IN2
â”œâ”€â”€ GPIO 15 â†’ CS â”œâ”€â”€ GPIO 27 â†’ IN3
â”œâ”€â”€ GPIO 2 â†’ DC â”œâ”€â”€ GPIO 14 â†’ IN4
â”œâ”€â”€ GPIO 4 â†’ RST â”œâ”€â”€ GPIO 32 â†’ ENA (PWM)
â””â”€â”€ 3.3V â†’ VCC + LED â””â”€â”€ GPIO 33 â†’ ENB (PWM)

SERVOS (Pan-Tilt Head): SENSORS:
â”œâ”€â”€ GPIO 19 â†’ Pan Servo â”œâ”€â”€ GPIO 5 â†’ US1 TRIG
â””â”€â”€ GPIO 21 â†’ Tilt Servo â”œâ”€â”€ GPIO 34 â†’ US1 ECHO
â”œâ”€â”€ GPIO 0 â†’ US2 TRIG
LED STRIP (WS2812B): â”œâ”€â”€ GPIO 35 â†’ US2 ECHO
â””â”€â”€ GPIO 13 â†’ DATA â”œâ”€â”€ GPIO 36 â†’ IR Left
â””â”€â”€ GPIO 39 â†’ IR Right
BUZZER:
â””â”€â”€ GPIO 12 â†’ Signal BATTERY MONITOR:
â””â”€â”€ GPIO 39 â†’ ADC (Voltage Divider)
DFPLAYER MINI:
â”œâ”€â”€ GPIO 17 â†’ TX (ESPâ†’DF) POWER:
â””â”€â”€ GPIO 16 â†’ RX (DFâ†’ESP) â”œâ”€â”€ VIN â† 5V (from L298N regulator)
â””â”€â”€ GND â† Common Ground

text


### Power System
18650 Battery Pack (2S2P):
7.4V, ~5000mAh
â”‚
â”œâ”€â”€ Rocker Switch (ON/OFF)
â”‚
â”œâ”€â”€ 2S BMS (overcharge/discharge protection)
â”‚
â”œâ”€â”€â–º L298N Motor Driver (7.4V input)
â”‚ â”œâ”€â”€ Motors (get ~6V after driver drop)
â”‚ â””â”€â”€ 5V Regulator Output
â”‚ â”œâ”€â”€ ESP32 (via VIN)
â”‚ â”œâ”€â”€ Servos
â”‚ â”œâ”€â”€ LED Strip
â”‚ â”œâ”€â”€ DFPlayer
â”‚ â”œâ”€â”€ Sensors
â”‚ â””â”€â”€ Buzzer
â”‚
â”œâ”€â”€â–º Voltage Divider (10kÎ© + 10kÎ©)
â”‚ â””â”€â”€ ESP32 ADC (battery monitoring)
â”‚
â””â”€â”€â–º TP4056 Modules (for charging)
â””â”€â”€ Micro-USB input from wall charger

Estimated Runtime: 3-4 hours (typical use)
Charging Time: ~2-3 hours

text


---

## ğŸ§  ML Models

| # | Model | Task | Type | Dataset | Key Metric |
|---|---|---|---|---|---|
| 1 | YOLOv5-nano | Object Detection | Pre-trained + fine-tuned | COCO | mAP |
| 2 | MediaPipe Face Mesh | 468-point Face Landmarks | Pre-trained | Google | Detection Accuracy |
| 3 | MediaPipe Pose | 33-point Body Pose Estimation | Pre-trained | Google | Keypoint Confidence |
| 4 | MediaPipe Hands + Custom Classifier | Hand Gesture Recognition | Pre-trained + Custom | Google + Custom | Gesture Accuracy |
| 5 | dlib ResNet / FaceNet | Face Recognition (128-d embeddings) | Pre-trained + Custom DB | LFW + Custom | FAR / FRR |
| 6 | Custom CNN (2D Conv) | Audio Event Classification | Trained from scratch | UrbanSound8K / ESC-50 | F1-Score, Accuracy |
| 7 | Vosk / Google Speech API | Speech-to-Text | Pre-trained | â€” | WER |
| 8 | Gemini 2.0 Flash (LLM) | NLU + Conversation + Humor | Pre-trained API | Google | Response Relevance |
| 9 | Random Forest / XGBoost | Network Anomaly Detection | Trained | NSL-KDD / CICIDS2017 | ROC-AUC, Precision |
| 10 | Weighted Ensemble | Multi-modal Sensor Fusion | Custom Designed | â€” | Detection Accuracy, FAR |

### Model Details

#### 1. Object Detection (YOLOv5-nano)
Architecture: YOLOv5-nano (1.9M parameters)
Input: 640Ã—640 RGB frame
Output: Bounding boxes + class labels + confidence
Classes: 80 COCO classes (person, car, dog, etc.)
Speed: ~30ms per frame on CPU
Use: Detecting people, vehicles, animals in surveillance mode
Module: optic.py â†’ detect_objects()

text


#### 2-4. MediaPipe Suite
Face Mesh: 468 3D facial landmarks, real-time
Pose: 33 body keypoints, full skeleton
Hands: 21 keypoints per hand, up to 2 hands
All run on CPU, no GPU required
Module: optic.py â†’ wireframe(), bone_rip()

text


#### 5. Face Recognition
Method: 128-dimensional face embedding comparison
Encoding: dlib's ResNet face encoder
Matching: Euclidean distance
Threshold: 0.5 (adjustable in dna.py)
Database: Local known_faces/ directory + SQLite
Classification: Safe (green) / Unknown (blue) / Threat (red)
Module: optic.py â†’ phantom_trace()

text


#### 6. Audio Classification CNN
Architecture:
â”œâ”€â”€ Input: 128Ã—128 Mel Spectrogram (1 channel)
â”œâ”€â”€ Conv2D(32, 3Ã—3) â†’ ReLU â†’ MaxPool(2Ã—2)
â”œâ”€â”€ Conv2D(64, 3Ã—3) â†’ ReLU â†’ MaxPool(2Ã—2)
â”œâ”€â”€ Conv2D(64, 3Ã—3) â†’ ReLU â†’ MaxPool(2Ã—2)
â”œâ”€â”€ Flatten
â”œâ”€â”€ Dense(128) â†’ ReLU â†’ Dropout(0.3)
â””â”€â”€ Dense(10) â†’ Softmax

Features: Mel Spectrogram
Classes: air_conditioner, car_horn, children_playing,
dog_bark, drilling, engine_idling, gun_shot,
jackhammer, siren, street_music
Dataset: UrbanSound8K (8,732 samples)
Training: 80/20 split, 30 epochs, Adam optimizer
Module: echo_hunter.py â†’ freq_hunt()

text


#### 9. Network Anomaly Detection
Model: Random Forest (100 estimators)
Features: Numeric traffic features from packet headers
Dataset: NSL-KDD (125,973 training samples)
Classes: Normal vs Anomalous traffic
Module: ice_wall.py â†’ train_anomaly_model()

text


#### 10. Sensor Fusion
Inputs:
â”œâ”€â”€ Visual threat score (0-1) from face recognition
â”œâ”€â”€ Audio threat score (0-1) from sound classification
â”œâ”€â”€ Network threat score (0-1) from anomaly detection
â”œâ”€â”€ Proximity alert (0/1) from ultrasonic sensors

Weights: visual=0.35, audio=0.30, network=0.20, proximity=0.15
Fusion: Weighted average with time-decay
Output: doom_level (0-1)
Threshold: > 0.7 = ALERT
Module: hivemind.py â†’ _recalculate()

text


---

## ğŸ› ï¸ Tech Stack

### Software
LANGUAGE â”‚ PURPOSE
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Python 3.10+ â”‚ Main server, ML models
C++ (Arduino) â”‚ ESP32 firmware
HTML/CSS â”‚ Dashboard styling (inline)
SQL â”‚ Database queries

FRAMEWORK/LIBRARY â”‚ PURPOSE
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
OpenCV â”‚ Image processing
MediaPipe â”‚ Face mesh, pose, hands
face_recognition â”‚ Face detection + recognition
dlib â”‚ Face encoding (ResNet)
Ultralytics â”‚ YOLOv5 object detection
TensorFlow/Keras â”‚ Audio classification CNN
librosa â”‚ Audio feature extraction
scikit-learn â”‚ Network anomaly models
Vosk â”‚ Offline speech recognition
pyttsx3 â”‚ Text-to-speech engine
google-genai â”‚ Gemini 2.0 Flash LLM API
paho-mqtt â”‚ MQTT communication
Streamlit â”‚ Cyberpunk dashboard
pandas â”‚ Data processing
SQLite3 â”‚ Event/alert database
scapy â”‚ Network packet analysis
yt-dlp â”‚ Music search/download
pygame â”‚ Audio playback
sounddevice â”‚ Audio recording
joblib â”‚ Model serialization

ARDUINO LIBRARIES â”‚ PURPOSE
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
TFT_eSPI â”‚ TFT display (eye animations)
Adafruit NeoPixel â”‚ WS2812B LED strip control
PubSubClient â”‚ MQTT client
ArduinoJson â”‚ JSON parsing
ESP32Servo â”‚ Servo motor control
DFRobotDFPlayerMiniâ”‚ MP3 sound effects

text


### Hardware Architecture
SERVER LAYER: Personal Laptop (Python + ML)
NETWORK LAYER: WiFi Router (MQTT + HTTP)
CONTROLLER LAYER: ESP32-WROOM-32 (Motor + Sensor + Display)
SENSOR LAYER: Redmi Note 12 (Camera + Mic)
DISPLAY LAYER: UP Govt Tablet (Dashboard) + TFT (Eyes)
ACTUATOR LAYER: Motors + Servos + LEDs + Speaker + Buzzer
POWER LAYER: 18650 2S2P Pack (7.4V) + BMS + TP4056

text


---

## ğŸ“– Codex

Every file and function in JINX uses cyberpunk-inspired codenames. 
See [CODEX.md](CODEX.md) for the full naming reference.

### Quick Reference

   | Module | Codename | Purpose |
   |---|---|---|
   | `genesis.py` | GENESIS | Main startup â€” launches everything |
   | `dna.py` | DNA | Configuration and settings |
   | `blackbox.py` | BLACKBOX | SQLite database logging |
   | `psyche.py` | PSYCHE | Personality lines and prompts |
   | `optic.py` | OPTIC | Vision â€” camera, face, pose, mesh |
   | `vocoder.py` | VOCODER | Voice â€” STT, TTS, Gemini, commands |
   | `echo_hunter.py` | ECHO HUNTER | Audio â€” sound classification CNN |
   | `ice_wall.py` | ICE WALL | Network â€” device scan, anomaly detection |
   | `synapse.py` | SYNAPSE | MQTT â€” central message routing |
   | `hivemind.py` | HIVEMIND | Sensor fusion â€” combined threat scoring |
   | `nexus.py` | NEXUS | Cyberpunk command center dashboard |

---

## ğŸ“ Project Structure
J.I.N.X/
â”‚
â”œâ”€â”€ server/
â”‚ â”œâ”€â”€ genesis.py # GENESIS â€” main startup, launches all modules
â”‚ â”œâ”€â”€ dna.py # DNA â€” config, IPs, API keys, thresholds
â”‚ â”œâ”€â”€ blackbox.py # BLACKBOX â€” sqlite database logging
â”‚ â”œâ”€â”€ psyche.py # PSYCHE â€” personality lines + gemini prompts
â”‚ â”œâ”€â”€ optic.py # OPTIC â€” camera, face detection/recognition,
â”‚ â”‚ # pose, mesh, object detection, HUD
â”‚ â”œâ”€â”€ vocoder.py # VOCODER â€” speech recognition, tts, gemini
â”‚ â”‚ # voice commands, roasts, music
â”‚ â”œâ”€â”€ echo_hunter.py # ECHO HUNTER â€” audio classification CNN,
â”‚ â”‚ # mel spectrogram, sound patrol
â”‚ â”œâ”€â”€ ice_wall.py # ICE WALL â€” network scanning, device detection,
â”‚ â”‚ # anomaly model training
â”‚ â”œâ”€â”€ synapse.py # SYNAPSE â€” central mqtt handler, state tracking,
â”‚ â”‚ # cross-module message routing
â”‚ â””â”€â”€ hivemind.py # HIVEMIND â€” sensor fusion, doom_level scoring,
â”‚ # weighted threat assessment
â”‚
â”œâ”€â”€ dashboard/
â”‚ â””â”€â”€ nexus.py # NEXUS â€” streamlit cyberpunk command center
â”‚ # real-time dashboard with neon UI
â”‚
â”œâ”€â”€ arduino/
â”‚ â””â”€â”€ jinx_esp32/
â”‚ â”œâ”€â”€ jinx_esp32.ino # Main ESP32 firmware
â”‚ â”œâ”€â”€ config.h # Pin definitions + WiFi credentials
â”‚ â”œâ”€â”€ eyes.h # Eye animation functions (11 states)
â”‚ â”œâ”€â”€ motors.h # Motor control (surge, retreat, halt)
â”‚ â”œâ”€â”€ leds.h # LED strip patterns (15+ modes)
â”‚ â”œâ”€â”€ sensors.h # Ultrasonic + IR sensor reading
â”‚ â””â”€â”€ servos.h # Head pan-tilt servo control
â”‚
â”œâ”€â”€ models/
â”‚ â”œâ”€â”€ audio_classifier.h5 # Trained audio CNN (generated by training)
â”‚ â”œâ”€â”€ network_anomaly.pkl # Trained network model (generated by training)
â”‚ â”œâ”€â”€ yolov5n.pt # YOLOv5 nano weights (auto-downloaded)
â”‚ â””â”€â”€ vosk-model/ # Offline speech recognition model (downloaded)
â”‚
â”œâ”€â”€ training/
â”‚ â”œâ”€â”€ train_audio_cnn.py # Audio model training on UrbanSound8K
â”‚ â”œâ”€â”€ train_network_model.py # Network anomaly model on NSL-KDD
â”‚ â””â”€â”€ evaluate_models.py # Model evaluation + metrics generation
â”‚
â”œâ”€â”€ data/
â”‚ â”œâ”€â”€ known_faces/ # Registered face images (name.jpg)
â”‚ â”œâ”€â”€ alerts/ # Alert screenshots (auto-generated)
â”‚ â”œâ”€â”€ urbansound8k/ # Audio training dataset (downloaded)
â”‚ â”œâ”€â”€ nsl-kdd/ # Network training dataset (downloaded)
â”‚ â””â”€â”€ jinx_database.db # SQLite database (auto-generated)
â”‚
â”œâ”€â”€ assets/
â”‚ â””â”€â”€ sounds/ # MP3 files for DFPlayer SD card
â”‚ â”œâ”€â”€ 001_boot.mp3
â”‚ â”œâ”€â”€ 002_alert.mp3
â”‚ â”œâ”€â”€ 003_happy.mp3
â”‚ â”œâ”€â”€ 004_threat.mp3
â”‚ â”œâ”€â”€ 005_sleepy.mp3
â”‚ â””â”€â”€ 006_ambient.mp3
â”‚
â”œâ”€â”€ docs/
â”‚ â”œâ”€â”€ report.pdf # Final project report
â”‚ â”œâ”€â”€ presentation.pptx # Demo day presentation
â”‚ â”œâ”€â”€ wiring_diagram.png # Hardware wiring diagram
â”‚ â”œâ”€â”€ architecture_diagram.png # System architecture diagram
â”‚ â””â”€â”€ demo_video.mp4 # Recorded demo backup
â”‚
â”œâ”€â”€ requirements.txt # Python dependencies
â”œâ”€â”€ README.md # This file
â”œâ”€â”€ CODEX.md # Naming convention reference
â”œâ”€â”€ LICENSE # MIT License
â””â”€â”€ .gitignore # Git ignore rules

text


---

## âš¡ Installation

### Prerequisites
Personal Laptop (Linux/Windows/Mac)
Python 3.10+
Arduino IDE 2.x
Git
Assembled JINX robot hardware
WiFi Router configured
Redmi Note 12 with IP Webcam app
UP Govt Tablet with browser
Mosquitto MQTT broker
text


### Step 1: Clone Repository

```bash
git clone https://github.com/Sidvortex/J.I.N.X.git
cd J.I.N.X
Step 2: Install Dependencies
Bash

# Arch/EndeavourOS:
sudo pacman -S python python-pip python-numpy python-opencv
sudo pacman -S python-scikit-learn python-pandas python-pillow
sudo pacman -S python-pygame python-pyaudio python-requests
sudo pacman -S mosquitto yt-dlp mpv

# Remaining via pip:
pip install face-recognition ultralytics paho-mqtt pyttsx3
pip install SpeechRecognition google-genai streamlit librosa
pip install sounddevice plotly flask joblib scapy vosk

# OR install everything from requirements.txt:
pip install -r requirements.txt
Step 3: Start MQTT Broker
Bash

sudo systemctl start mosquitto
sudo systemctl enable mosquitto
Step 4: Download ML Models
Bash

# YOLOv5 (auto-downloads on first run)
python -c "from ultralytics import YOLO; YOLO('yolov5n.pt')"

# Vosk speech model (offline STT)
# Download from: https://alphacephei.com/vosk/models
# Extract to: models/vosk-model/
Step 5: Configure
Bash

# Edit server/dna.py:
# - Set LAPTOP_IP to your laptop's IP
# - Set GEMINI_API_KEY (get from https://aistudio.google.com/)
# - Set PHONE_IP to your Redmi's static IP
# - Add face labels to FACE_LABELS dict
Step 6: Flash ESP32
text

1. Open Arduino IDE
2. Open arduino/jinx_esp32/jinx_esp32.ino
3. Install libraries: TFT_eSPI, Adafruit NeoPixel,
   PubSubClient, ArduinoJson, ESP32Servo, DFPlayerMini
4. Configure TFT_eSPI User_Setup.h for ILI9341
5. Select Board: ESP32 Dev Module
6. Upload
Step 7: Setup Phone
text

1. Install "IP Webcam" from Play Store on Redmi Note 12
2. Connect to WiFi router (set static IP in dna.py)
3. Open IP Webcam â†’ Start Server
4. Verify: http://PHONE_IP:8080/video in browser
Step 8: Register Faces
Bash

# Add face images to data/known_faces/
# Filename = person's name (without extension = database key)
# Example: data/known_faces/admin.jpg

# Update labels in server/dna.py:
FACE_LABELS = {
    "admin": "safe",
    "friend_name": "safe",
    "threat_person": "threat"
}
ğŸš€ Usage
Starting JINX
Bash

# Terminal 1: Start MQTT Broker (if not running)
sudo systemctl start mosquitto

# Terminal 2: Start JINX
cd J.I.N.X
python server/genesis.py

# Terminal 3: Start Dashboard (genesis.py does this automatically,
# but you can also start manually)
streamlit run dashboard/nexus.py --server.port 8501

# On Tablet: Open browser â†’ http://LAPTOP_IP:8501
# On Phone: Start IP Webcam
# On Robot: Power ON (rocker switch)
Startup Flags
Bash

# Normal startup (all modules)
python server/genesis.py

# Start in sentinel mode
python server/genesis.py --sentinel

# Skip specific modules
python server/genesis.py --no-vision      # skip camera
python server/genesis.py --no-voice       # skip voice
python server/genesis.py --no-audio       # skip audio classification
python server/genesis.py --no-network     # skip network monitoring
python server/genesis.py --no-dashboard   # skip dashboard

# Combine flags
python server/genesis.py --no-vision --no-audio

# Test individual modules
python server/optic.py          # vision only
python server/vocoder.py        # voice only
python server/echo_hunter.py    # audio only
python server/ice_wall.py       # network only
Boot Sequence
text

     â–ˆâ–ˆâ•—â–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ•—   â–ˆâ–ˆâ•—â–ˆâ–ˆâ•—  â–ˆâ–ˆâ•—
     â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•
     â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â–ˆâ–ˆâ•— â–ˆâ–ˆâ•‘ â•šâ–ˆâ–ˆâ–ˆâ•”â• 
â–ˆâ–ˆ   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘ â–ˆâ–ˆâ•”â–ˆâ–ˆâ•— 
â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘ â•šâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â• â–ˆâ–ˆâ•—
 â•šâ•â•â•â•â• â•šâ•â•â•šâ•â•  â•šâ•â•â•â•â•šâ•â•  â•šâ•â•

  JUDGMENTAL INTELLIGENCE WITH
  NEURAL EXECUTION  v2.0.77

[INIT] Loading SYNAPSE (MQTT Broker).......... âœ“
[INIT] Loading BLACKBOX (Database)............ âœ“
[INIT] Loading PSYCHE (Personality Matrix).... âœ“
[INIT] Loading OPTIC (Visual Cortex).......... âœ“
[INIT] Loading VOCODER (Voice System)......... âœ“
[INIT] Loading ECHO (Sound Detection)......... âœ“
[INIT] Loading ICE (Network Defense).......... âœ“
[INIT] Loading HIVEMIND (Sensor Fusion)....... âœ“

âš¡ JINX NEURAL CORE ONLINE âš¡
Voice Commands
text

"Hey JINX, wake up"              â†’ System activation
"Hey JINX, guard mode"           â†’ Sentinel surveillance mode
"Hey JINX, buddy mode"           â†’ Switch to buddy mode
"Hey JINX, roast [name]"         â†’ AI-generated roast
"Hey JINX, play music"           â†’ Music playback
"Hey JINX, lights [color]"       â†’ LED control
"Hey JINX, come here"            â†’ Move forward
"Hey JINX, go back"              â†’ Move backward
"Hey JINX, stop"                 â†’ Stop movement
"Hey JINX, register [name]"      â†’ Save new face
"Hey JINX, status"               â†’ System health check
"Hey JINX, goodnight"            â†’ Sleep mode
ğŸ¬ Demo Day
Room Setup
text

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  â–‘â–‘â–‘â–‘â–‘â–‘ LED STRIPS (PURPLE BREATHING) â–‘â–‘â–‘â–‘â–‘ â”‚
â”‚                                              â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚   â”‚ LAPTOP  â”‚  â”‚   TABLET     â”‚              â”‚
â”‚   â”‚ genesis â”‚  â”‚   NEXUS      â”‚              â”‚
â”‚   â”‚ terminalâ”‚  â”‚  dashboard   â”‚              â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚                                              â”‚
â”‚          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                        â”‚
â”‚          â”‚ J.I.N.X. â”‚  â† The Star            â”‚
â”‚          â”‚   ğŸ¤–     â”‚                        â”‚
â”‚          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                        â”‚
â”‚                           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚                           â”‚CHARGINGâ”‚         â”‚
â”‚                           â”‚ DOCK   â”‚         â”‚
â”‚                           â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â”‚                                              â”‚
â”‚  â–‘â–‘â–‘â–‘â–‘â–‘ LED STRIPS (PURPLE BREATHING) â–‘â–‘â–‘â–‘â–‘ â”‚
â”‚                                              â”‚
â”‚       ğŸ‘¥ AUDIENCE ğŸ‘¥                         â”‚
â”‚                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Demo Script
text

1. Room is dark. LED strips breathing purple.
2. "Hey JINX, wake up."
   â†’ Boot animation, eyes open, LEDs flash cyan
3. Step in front â†’ face recognized â†’ green box â†’ "Hey boss!"
4. Friend steps in â†’ unknown â†’ blue box â†’ scanned and logged
5. "Hey JINX, roast [friend]" â†’ AI roast delivered
6. "Hey JINX, guard mode" â†’ scanning eyes, surveillance active
7. Play glass breaking sound â†’ threat detected â†’ red alert
8. "Hey JINX, play music" â†’ music + LED light show
9. "Hey JINX, lights purple" â†’ room changes color
10. "Hey JINX, goodnight" â†’ sleepy eyes â†’ system standby
ğŸ”‹ Power Specifications
text

Battery: 4Ã— 18650 Li-ion (2S2P)
Voltage: 7.4V nominal (8.4V full, 6.0V cutoff)
Capacity: ~5000mAh
Runtime: 3-4 hours (typical)
Charging: TP4056 via Micro-USB (5V 1A)
Charge Time: 2-3 hours
Protection: 2S BMS (overcharge, over-discharge, short circuit)
Monitoring: ESP32 ADC via voltage divider â†’ vitals()
ğŸ’° Budget
Category	Cost (â‚¹)
Metal Tank Chassis Kit	900
ESP32 + Display	800
Servos + Motor Driver	290
Sensors + Buzzer	225
Battery + BMS + Charger + Switch	565
DFPlayer + Speaker	160
LED Strip	250
Wiring + Breadboard	230
Build Materials	330
Total	~â‚¹3,750
Recycled components from ThinkPad T61, spare phone, existing
peripherals saved an estimated â‚¹15,000+ in equivalent hardware costs.

ğŸ“Š Results & Metrics
Model	Metric	Score
YOLOv5-nano	mAP@0.5	28.0% (COCO)
Face Recognition	Accuracy	~95%+
Face Recognition	False Acceptance Rate	<2%
Pose Estimation	Keypoint Confidence	~90%+
Audio CNN	F1-Score	~85%+
Audio CNN	Accuracy	~88%+
Network Anomaly	ROC-AUC	~92%+
Voice Recognition	Word Error Rate	~10-15%
Sensor Fusion	Overall Detection Accuracy	~90%+
Metrics to be updated after final training and evaluation.

ğŸ”® Future Scope
text

â”œâ”€â”€ Spider leg mechanism (servo-based hexapod conversion)
â”œâ”€â”€ SLAM-based room mapping and path planning
â”œâ”€â”€ Raspberry Pi 4 integration for on-robot ML processing
â”œâ”€â”€ Robotic arm attachment for object manipulation
â”œâ”€â”€ Multi-robot swarm communication
â”œâ”€â”€ Cloud dashboard for remote monitoring
â”œâ”€â”€ Mobile app for remote control
â”œâ”€â”€ Emotion detection from facial expressions
â”œâ”€â”€ Multi-language voice support (Hindi + English)
â”œâ”€â”€ Integration with smart home ecosystems (Google Home, Alexa)
â””â”€â”€ 3D-printed custom chassis upgrade
ğŸ‘¨â€ğŸ’» Author
text

Sidvortex
B.Tech Data Science (2023-2027)

GitHub: github.com/Sidvortex
ğŸ“œ License
This project is licensed under the MIT License â€” see the LICENSE file for details.

ğŸ™ Acknowledgments
text

â”œâ”€â”€ Google MediaPipe team (vision models)
â”œâ”€â”€ Ultralytics (YOLOv5)
â”œâ”€â”€ dlib / face_recognition library
â”œâ”€â”€ Google Gemini AI
â”œâ”€â”€ DFRobot (DFPlayer Mini)
â”œâ”€â”€ Espressif Systems (ESP32)
â”œâ”€â”€ The dead ThinkPad T61 that gave its body for science
â”œâ”€â”€ Open-source community
â””â”€â”€ [Your Professor's Name] (Project Guide)
<div align="center">
Built with â™¥, sarcasm, and â‚¹3,750 worth of components.

JINX doesn't just think. It judges.

âš¡ğŸ¤–âš¡

</div> ```